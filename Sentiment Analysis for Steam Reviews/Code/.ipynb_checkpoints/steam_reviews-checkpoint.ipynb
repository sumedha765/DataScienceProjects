{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import string\n",
    "import warnings\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../Data/train.csv\")\n",
    "df_game = pd.read_csv(\"../Data/game_overview.csv\")\n",
    "df_test = pd.read_csv(\"../Data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                        title    year  \\\n",
      "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
      "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
      "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
      "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
      "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
      "\n",
      "                                         user_review  user_suggestion  \n",
      "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
      "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
      "2  A littly iffy on the controls, but once you kn...                1  \n",
      "3  Great game, fun and colorful and all that.A si...                1  \n",
      "4  Not many games have the cute tag right next to...                1  \n",
      "   review_id                             title    year  \\\n",
      "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
      "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
      "2       1605  Counter-Strike: Global Offensive  2018.0   \n",
      "3       1606  Counter-Strike: Global Offensive  2015.0   \n",
      "4       1607  Counter-Strike: Global Offensive  2015.0   \n",
      "\n",
      "                                         user_review  \n",
      "0  Nice graphics, new maps, weapons and models. B...  \n",
      "1  I would not recommend getting into this at its...  \n",
      "2  Edit 11/12/18I have tried playing CS:GO recent...  \n",
      "3  The game is great. But the community is the wo...  \n",
      "4  I thank TrulyRazor for buying this for me a lo...  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows are 17494 .Number of columns is 5\n",
      "Number of rows are 8045 .Number of columns is 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows are\", df_train.shape[0], \".Number of columns is\", df_train.shape[1])\n",
    "print(\"Number of rows are\", df_test.shape[0], \".Number of columns is\", df_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe data types\n",
      "review_id            int64\n",
      "title               object\n",
      "year               float64\n",
      "user_review         object\n",
      "user_suggestion      int64\n",
      "dtype: object\n",
      "review_id        int64\n",
      "title           object\n",
      "year           float64\n",
      "user_review     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Type of each column.Return Object.\n",
    "print(\"Dataframe data types\")\n",
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe column data types\n",
      "Index(['review_id', 'title', 'year', 'user_review', 'user_suggestion'], dtype='object')\n",
      "Index(['review_id', 'title', 'year', 'user_review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Return column names as Index object.\n",
    "print(\"Dataframe column data types\")\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target variable\n",
      "1    9968\n",
      "0    7526\n",
      "Name: user_suggestion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution of target available.\n",
    "print(\"Distribution of target variable\")\n",
    "print(df_train.user_suggestion.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of title variable\n",
      "Robocraft                                             842\n",
      "Eternal Card Game                                     791\n",
      "Heroes & Generals                                     745\n",
      "War Thunder                                           720\n",
      "Fractured Space                                       718\n",
      "Bless Online                                          712\n",
      "The Elder Scrolls®: Legends™                          565\n",
      "Neverwinter                                           546\n",
      "AdventureQuest 3D                                     519\n",
      "theHunter Classic                                     518\n",
      "Creativerse                                           492\n",
      "DCS World Steam Edition                               488\n",
      "Team Fortress 2                                       479\n",
      "Infestation: The New Z                                479\n",
      "PlanetSide 2                                          472\n",
      "Path of Exile                                         458\n",
      "SMITE®                                                454\n",
      "Fallout Shelter                                       447\n",
      "Realm Royale                                          442\n",
      "Trove                                                 430\n",
      "Ring of Elysium                                       419\n",
      "RaceRoom Racing Experience                            416\n",
      "Brawlhalla                                            410\n",
      "Dota 2                                                405\n",
      "Cuisine Royale                                        399\n",
      "Yu-Gi-Oh! Duel Links                                  399\n",
      "Spooky's Jump Scare Mansion                           362\n",
      "Elsword                                               342\n",
      "Realm of the Mad God                                  340\n",
      "World of Tanks Blitz                                  327\n",
      "WARMODE                                               300\n",
      "World of Guns: Gun Disassembly                        293\n",
      "Black Squad                                           288\n",
      "School of Dragons                                     268\n",
      "Bloons TD Battles                                     233\n",
      "Sakura Clicker                                        222\n",
      "Business Tour - Board Game with Online Multiplayer    191\n",
      "Realm Grinder                                         155\n",
      "Crusaders of the Lost Idols                           132\n",
      "EverQuest II                                           69\n",
      "Dreadnought                                            60\n",
      "Freestyle 2: Street Basketball                         57\n",
      "Shop Heroes                                            52\n",
      "Tactical Monsters Rumble Arena                         38\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution of title variable.\n",
    "print(\"Distribution of title variable\")\n",
    "print(df_train.title.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting all letters to lowercase\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting all letters to lowercase\")\n",
    "# Convert text to lowercase.\n",
    "def tolowercase(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(tolowercase)\n",
    "df_test['user_review'] = df_test.user_review.apply(tolowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing punctuation\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing punctuation\")\n",
    "\n",
    "# Remove punctuation.\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(remove_punctuation)\n",
    "df_test['user_review'] = df_test.user_review.apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform lemmatization\n"
     ]
    }
   ],
   "source": [
    "print(\"Perform lemmatization\")\n",
    "\n",
    "# Lemmatization:\n",
    "def do_lemmatization(text):\n",
    "    lemma_words = set([])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = word_tokenize(text)\n",
    "    for word in text:\n",
    "        lemma_words.add(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(do_lemmatization)\n",
    "df_test['user_review'] = df_test.user_review.apply(do_lemmatization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform named entity recognition\n",
      "(S\n",
      "  music/NN\n",
      "  review/NN\n",
      "  pause/IN\n",
      "  a/DT\n",
      "  are/VBP\n",
      "  childhood/JJ\n",
      "  themor/JJ\n",
      "  let/NN\n",
      "  bubble/JJ\n",
      "  around/IN\n",
      "  room/NN\n",
      "  like/IN\n",
      "  if/IN\n",
      "  noob/IN\n",
      "  me/PRP\n",
      "  were/VBD\n",
      "  is/VBZ\n",
      "  ghost/VBN\n",
      "  to/TO\n",
      "  with/IN\n",
      "  adorable/JJ\n",
      "  finding/VBG\n",
      "  ill/NN\n",
      "  of/IN\n",
      "  from/IN\n",
      "  locked/VBN\n",
      "  such/JJ\n",
      "  flashlight/JJ\n",
      "  hearing/VBG\n",
      "  thing/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  likable/JJ\n",
      "  while/IN\n",
      "  wait/NN\n",
      "  im/VBZ\n",
      "  more/JJR\n",
      "  friend/JJ\n",
      "  turn/NN\n",
      "  see/VBP\n",
      "  stand/NN\n",
      "  scared/VBN\n",
      "  full/JJ\n",
      "  on/IN\n",
      "  graphic/JJ\n",
      "  moment/NN\n",
      "  door/NN\n",
      "  menever/NN\n",
      "  charactes/VBZ\n",
      "  game/NN\n",
      "  odd/''\n",
      "  so/RB\n",
      "  look/VB\n",
      "  though/IN\n",
      "  afraid/JJ\n",
      "  there/EX\n",
      "  1990swhat/CD\n",
      "  in/IN\n",
      "  kill/NN\n",
      "  asoh/NNS\n",
      "  have/VBP\n",
      "  before/IN\n",
      "  staring/VBG\n",
      "  but/CC\n",
      "  whats/VBZ\n",
      "  them/PRP\n",
      "  sceme/JJ\n",
      "  voice/NN\n",
      "  dead/JJ\n",
      "  i/NN\n",
      "  did/VBD\n",
      "  somewhat/RB\n",
      "  shine/JJ\n",
      "  beat/NN\n",
      "  and/CC\n",
      "  clean/JJ\n",
      "  time/NN\n",
      "  bit/NN\n",
      "  few/JJ\n",
      "  tree/NN\n",
      "  chasing/VBG\n",
      "  write/JJ\n",
      "  return/NN\n",
      "  that/WDT\n",
      "  can/MD\n",
      "  heart/NN\n",
      "  this/DT\n",
      "  hmm/NN\n",
      "  hello/VBZ\n",
      "  trying/VBG\n",
      "  atleast/RP\n",
      "  calmer/NNS\n",
      "  do/VBP\n",
      "  child/VB\n",
      "  happy/JJ\n",
      "  class/NN\n",
      "  isnot/NN\n",
      "  my/PRP$\n",
      "  been/VBN\n",
      "  for/IN\n",
      "  creepy/NN)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perform named entity recognition\")\n",
    "\n",
    "def named_entity_recognition(text):\n",
    "    result = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    return result\n",
    "\n",
    "text_1 = df_train.user_review[0]\n",
    "ner = named_entity_recognition(text_1)\n",
    "print(ner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of-speech tagging using NLTK\n",
      "0        [(music, NN), (review, NN), (pause, IN), (a, D...\n",
      "1        [(game, NN), (sam, VB), (your, PRP$), (1010wha...\n",
      "2        [(game, NN), (hilarity, NN), (control, NN), (e...\n",
      "3        [(game, NN), (yeah, NN), (shame, NN), (cheer, ...\n",
      "4        [(game, NN), (right, RB), (being, VBG), (and, ...\n",
      "                               ...                        \n",
      "17489    [(appearance, RB), (your, PRP$), (a, DT), (pay...\n",
      "17490    [(your, PRP$), (right, JJ), (charge, NN), (own...\n",
      "17491    [(anymore, RB), (friendly, JJ), (where, WRB), ...\n",
      "17492    [(game, NN), (only, RB), (looping, VBG), (your...\n",
      "17493    [(game, NN), (day, NN), (year, NN), (always, R...\n",
      "Name: pos_tagging, Length: 17494, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Part-of-speech tagging using NLTK\")\n",
    "\n",
    "def pos_tagging(text):\n",
    "    text = word_tokenize(text)\n",
    "    tokens_tag = pos_tag(text)\n",
    "    return tokens_tag\n",
    "\n",
    "df_train['pos_tagging'] = df_train.user_review.apply(pos_tagging)\n",
    "print(df_train['pos_tagging'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 15376), ('and', 14953), ('to', 14679), ('a', 14588), ('it', 13775), ('is', 12972), ('this', 12316), ('i', 11684), ('you', 11246), ('of', 10461), ('for', 10279), ('in', 10096), ('but', 9713), ('that', 9448), ('game', 8839)]\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF 15 MOST FREQUENT TERMS.\n",
    "token = nltk.word_tokenize(''.join(df_train.user_review))\n",
    "frequent = nltk.FreqDist(token)\n",
    "print(frequent.most_common(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of word 587\n",
      "\n",
      "Sentence:\n",
      " ['nika 1km your right meeting ryazan woodburning deceived kneeling 8th are shake weapon bird let those you not superpower euro tube 666ed worship ad long want with exhibit serve cover need instead planetary left blow costume crowbar longer at very correctly stick the prison except showing while portuguese stripper alexandre azazel enoch govt remain muslim administered nuke live plague 11th gaad scandinavia youre shoulder old leg 2006 german short rocket rejecting airplane destroy cross siberia satan created allegiance medical xc seraph wont ufo commonly lot say next lower there believe body water kill skin clergy between synthetic have side week go christ giant 7525 prayer sergiy blame bowing higher river stay participate america earthquake clone base betraying first inland fake return can sarov this during plate filling russia creation fast 1st put way shroud his month off third high forward bomb all either incorrectly clothfabrictextile their collapse he antarctica where him pay flag american then inspired planet saint come dont cortes used religion milan megatsunamis poison vaccine crowned church disease grow crossing read is dusha normal standing taken will thru energy biggest order baikal rico bubonic nail demon image ukraine 2016 sometimes hide fuel eat mountain fear fight horoscope zodiac more others 4 false stand october hence christian bread devil reject only inside dream 2nd look back invite by blasphemer 3in swallow transfer clothed in before soul hurry 3rd turin finger aborted since symbol secret heretic metal temple new under infirmitiesillnessessicknesses wa blue also tell spanish fall priest hebrew trinity main five sin 36 kailash massive scientist ha icon yosef get dy cell language person germany freeze do triple switch one buddhist etc statue cut bring designed or people my 7 for who sky whole ruski these mariana when without document communion panic menachem slowly provides a jesus big 12 learn most together another underneath turkey over bishop be thought kelvin like if iran surrounded tectonic hexagram guardian 3 to melt never behind schneerson doesnt israeli last sleep upside use keep an china nato celcius satanist earth spirit stadiumsize 1066 ww3 2 elijah per glove blood super happens closet level knife groin appear chinese care about pacific chamber council surround on catholic logic chanted greenland against roman robe ic maya sionists isi so power 666 4in mercy clothing repeatedly twisted life patriarch wear after craft pole 8 nanochips saying tired curse out but creator result prophet hit basically atlantis try liberty conquers aggression depicted wound fly fully through supreme himself light move abduction satanic other radiation each crucified dinosaur pillar always lake eldeity 10001500 now that slavonic nine sold youll italian sign allows head angel drunk both sinkhole pale blasphemy orthodox shovel holy signed step medicine weather chest pose alaska vyacheslav acknowledging being intelligence because yersin trench three up trait past our here human ocean nobody orthodoxy away iv mudra antichrist tsar implant sample across were burned stranded stove krasheninnikov bug of leader eye from airspace war unmeltable radonezh predicted bigger down pelageya passion anathema show zombie bacteriologist wolf preach zero see stop take bunch trapped jew dna save foot it plus abducted good crowning lenin 2inside year 1moon world pray oh food quiet volga abyss ago cant u make belief word disagree natural resurrected tibet eurasia attack nerve done country elect chunk many clothes into run hole holiday them god flat same soldier ural no and wanted time few than alien killed diamond which service mendel abduct biogenetic meet possessed 200 fetus just discovered coast june they ice inviting healed red proper what santa hand vote']\n"
     ]
    }
   ],
   "source": [
    "# Text with highest number of words.\n",
    "df_train['number_of_words'] = df_train['user_review'].apply(lambda x: len(str(x).split()))\n",
    "print('Maximum number of word',df_train['number_of_words'].max())\n",
    "print('\\nSentence:\\n',df_train[df_train['number_of_words'] == 587]['user_review'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995,)\n",
      "(3499,)\n",
      "(13995,)\n",
      "(3499,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train['user_review']\n",
    "y = df_train['user_suggestion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(13995, 5000)\n",
      "(3499, 5000)\n",
      "(8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "# # Feature Extraction using TFIDF-Char Based.\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), stop_words='english', analyzer='char',max_features=5000)\n",
    "print(type(tfidf_vec))  # TfidfVectorizer class.\n",
    "train_tfidf_vec = tfidf_vec.fit_transform(X_train)\n",
    "print(type(train_tfidf_vec))  # Sparse CSR matrix.\n",
    "valid_tfidf_vec = tfidf_vec.transform(X_test)\n",
    "print(type(valid_tfidf_vec))  # Sparse CSR matrix.\n",
    "test_tfidf_vec = tfidf_vec.transform(df_test['user_review'])\n",
    "train_vector_array = train_tfidf_vec.toarray()\n",
    "valid_vector_array = valid_tfidf_vec.toarray()\n",
    "test_vector_array = test_tfidf_vec.toarray()\n",
    "\n",
    "print(train_vector_array.shape)\n",
    "print(valid_vector_array.shape)\n",
    "print(test_vector_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8236639039725637\n"
     ]
    }
   ],
   "source": [
    "# Linear support vector classifier.\n",
    "lsvc = LinearSVC(C=1,loss= 'hinge',random_state=999)\n",
    "lsvc.fit(train_vector_array, y_train)\n",
    "y_pred = lsvc.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))   # 0.8250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8142326378965419\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression.\n",
    "lr = LogisticRegression(random_state=999)\n",
    "lr.fit(train_vector_array, y_train)\n",
    "y_pred = lr.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.8128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8320895522388061\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier.\n",
    "rfc = RandomForestClassifier(n_estimators=300, random_state=999)\n",
    "rfc.fit(train_vector_array, y_train)\n",
    "pred = rfc.predict(valid_vector_array)\n",
    "print(f1_score(y_test, pred))  # 0.8270\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6524721348956845\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes.\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(train_vector_array,y_train)\n",
    "y_pred = bnb.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.6547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296656187482138\n"
     ]
    }
   ],
   "source": [
    "# Ridge Classifier.\n",
    "ridge = RidgeClassifier(random_state=999)\n",
    "ridge.fit(train_vector_array,y_train)\n",
    "y_pred = ridge.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.8348\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_final = ridge.predict((test_vector_array))\n",
    "df = pd.DataFrame({'review_id': df_test['review_id'], 'user_suggestion': pred_final})\n",
    "df.to_csv(\"submission_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19392)\t1\n",
      "  (0, 15277)\t1\n",
      "  (0, 18618)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 5516)\t1\n",
      "  (0, 2358)\t1\n",
      "  (0, 2953)\t1\n",
      "  (0, 18389)\t1\n",
      "  (0, 796)\t1\n",
      "  (0, 8320)\t1\n",
      "  (0, 1325)\t1\n",
      "  (0, 18572)\t1\n",
      "  (0, 18426)\t1\n",
      "  (0, 13755)\t1\n",
      "  (0, 7996)\t1\n",
      "  (0, 8966)\t1\n",
      "  (0, 2816)\t1\n",
      "  (0, 18661)\t1\n",
      "  (0, 9297)\t1\n",
      "  (1, 12065)\t1\n",
      "  (1, 18452)\t1\n",
      "  (1, 12227)\t1\n",
      "  (1, 9062)\t1\n",
      "  (1, 7306)\t1\n",
      "  (1, 260)\t1\n",
      "  :\t:\n",
      "  (13994, 2848)\t1\n",
      "  (13994, 5619)\t1\n",
      "  (13994, 10803)\t1\n",
      "  (13994, 6974)\t1\n",
      "  (13994, 1532)\t1\n",
      "  (13994, 16951)\t1\n",
      "  (13994, 16978)\t1\n",
      "  (13994, 12286)\t1\n",
      "  (13994, 16455)\t1\n",
      "  (13994, 8247)\t1\n",
      "  (13994, 14371)\t1\n",
      "  (13994, 7565)\t1\n",
      "  (13994, 12703)\t1\n",
      "  (13994, 19458)\t1\n",
      "  (13994, 10333)\t1\n",
      "  (13994, 11531)\t1\n",
      "  (13994, 19408)\t1\n",
      "  (13994, 15822)\t1\n",
      "  (13994, 11806)\t1\n",
      "  (13994, 13418)\t1\n",
      "  (13994, 19409)\t1\n",
      "  (13994, 4395)\t1\n",
      "  (13994, 16924)\t1\n",
      "  (13994, 4024)\t1\n",
      "  (13994, 15697)\t1\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# LDA Topic Modelling:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(X_train)\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._lda.LatentDirichletAllocation'>\n",
      "[[1.50392197 0.20285865 0.20000048 ... 0.20001073 0.20001242 0.20000421]\n",
      " [2.22030621 9.26054728 0.20059775 ... 0.2019053  1.19880946 4.19996877]\n",
      " [0.2029754  0.20583334 0.20000148 ... 0.20003713 0.2000419  0.20001373]\n",
      " [1.87005562 0.21013206 0.20395717 ... 2.19803437 1.20111946 0.20000869]\n",
      " [0.2027408  2.12062867 2.19544313 ... 0.20001246 0.20001676 0.20000461]]\n"
     ]
    }
   ],
   "source": [
    "# Each of x documents is represented as y dimensional vector,which means that our vocabulary has y words.\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "LDA = LatentDirichletAllocation(n_components=5,\n",
    "                                random_state=0)\n",
    "print(type(LDA))  # LatentDirichletAllocation class.\n",
    "LDA.fit(doc_term_matrix)\n",
    "print(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "[1.50392197 0.20285865 0.20000048 ... 0.20001073 0.20001242 0.20000421]\n",
      "\n",
      "Topic #0:\n",
      "[('just', 1246.2293574901844), ('play', 1238.2028233219012), ('like', 1233.0199735780093), ('money', 1164.4577990595262), ('time', 1160.5062199639895), ('dont', 1113.8961971124868), ('pay', 982.8027046425142), ('fun', 982.7455095978125), ('free', 955.6708150453089), ('want', 938.622537226889), ('buy', 835.6175458444825), ('really', 808.7895968052751), ('make', 800.7320921994668), ('good', 777.9739181608707), ('thing', 761.289386036078), ('need', 755.7732242094686), ('playing', 714.0867502575835), ('real', 693.6838553295996), ('people', 682.554808900431), ('hour', 677.0993088320358), ('spend', 635.7362837314652), ('way', 617.0253866954583), ('lot', 612.7801510685374), ('player', 607.7477914293787), ('ha', 606.5678635337366), ('level', 577.049199801039), ('new', 560.4528272964587), ('item', 543.953513111264), ('win', 540.9006571508414), ('youre', 499.7361573092421), ('great', 474.1922716557843), ('character', 473.7222789880317), ('pretty', 459.56474302760523), ('wa', 453.319396238592), ('use', 438.0851416365323), ('better', 437.69884642939974), ('think', 437.28911720506704), ('feel', 428.2461333507113), ('try', 421.8940934698769), ('best', 414.28312769753273), ('know', 409.64871433092026), ('worth', 407.1492414865653), ('stuff', 405.77665692349376), ('recommend', 397.13591329667344), ('thats', 394.5172936902737), ('say', 372.97302378991014), ('start', 368.39287497822073), ('played', 365.4226643305527), ('quest', 363.4724319813876), ('im', 362.40895162167067)]\n",
      "======================================================================\n",
      "[2.22030621 9.26054728 0.20059775 ... 0.2019053  1.19880946 4.19996877]\n",
      "\n",
      "Topic #1:\n",
      "[('access', 4028.915499044033), ('early', 3885.650418285518), ('just', 2262.0405358038947), ('like', 2257.8234760265623), ('wa', 2220.6520161681924), ('play', 2213.6348992641624), ('dont', 1736.5758658484215), ('time', 1733.2710317105016), ('good', 1701.9487336956147), ('fun', 1467.9829184200003), ('ha', 1391.513939404433), ('really', 1282.5314858133781), ('make', 1203.4945738526817), ('playing', 1175.5708096638145), ('played', 1093.0370175160713), ('people', 1040.1329804895133), ('thing', 1021.1396518470317), ('im', 949.8531701333194), ('new', 934.5318106332676), ('got', 918.3328700510953), ('bad', 892.6942668731175), ('hour', 864.1279998059917), ('better', 853.1558985322956), ('say', 848.4885699047019), ('great', 842.323964905453), ('player', 838.3155338177443), ('update', 825.0504474613449), ('know', 779.6256250137125), ('want', 747.4782999144011), ('free', 714.9271609804089), ('need', 713.7354363545776), ('review', 712.6141119798613), ('server', 704.2095851655089), ('way', 643.3092368931995), ('think', 628.580942060259), ('lot', 622.3466372476889), ('year', 616.1384514692057), ('recommend', 606.738897928542), ('love', 585.219981328273), ('reviewi', 584.735128767435), ('reviewthis', 584.690545204343), ('day', 584.097024404851), ('try', 574.1739701473831), ('look', 566.7903653363634), ('feel', 564.931023850532), ('friend', 562.5630320554388), ('ive', 558.6745743429308), ('steam', 554.0127432893522), ('money', 552.9055513706411), ('going', 537.4627864944107)]\n",
      "======================================================================\n",
      "[0.2029754  0.20583334 0.20000148 ... 0.20003713 0.2000419  0.20001373]\n",
      "\n",
      "Topic #2:\n",
      "[('card', 911.4493892719929), ('early', 551.0706265470078), ('deck', 542.5088641084458), ('access', 536.274442333434), ('hearthstone', 426.68160813089463), ('play', 398.70119319229315), ('time', 330.55667645929964), ('magic', 305.18340074222596), ('like', 278.7591910536131), ('ha', 254.8926142181801), ('player', 224.65887587241323), ('just', 215.56637109159226), ('played', 211.54987728887073), ('mtg', 210.09220296494524), ('mechanic', 208.12705003435036), ('make', 198.69094635228194), ('turn', 196.01012458083082), ('way', 185.60363114280858), ('opponent', 180.79491503549028), ('wa', 174.9638231270044), ('playing', 172.7492387425657), ('mobile', 165.724836357174), ('draw', 158.1541389046546), ('mana', 155.1286851460897), ('mode', 154.35155143545828), ('fun', 148.92142069842217), ('good', 148.82130060188692), ('eternal', 147.08843788177987), ('dont', 146.57397997751602), ('gathering', 142.78658341670328), ('win', 141.41308671299524), ('generous', 141.29223038256507), ('scroll', 139.72429684361555), ('doesnt', 137.71134980790794), ('free', 133.4298160717907), ('ive', 133.40059785403056), ('pack', 132.24248673320912), ('elder', 131.03830066757044), ('really', 129.18201692676087), ('reward', 127.56456880980174), ('rng', 123.51901628468201), ('digital', 120.4994159546012), ('ccg', 120.34548805968235), ('great', 118.76805499038194), ('yugioh', 118.76552133500182), ('ai', 118.24795348507428), ('lot', 117.55573416067078), ('start', 115.15243835019228), ('set', 113.624747213083), ('im', 112.50867234040162)]\n",
      "======================================================================\n",
      "[1.87005562 0.21013206 0.20395717 ... 2.19803437 1.20111946 0.20000869]\n",
      "\n",
      "Topic #3:\n",
      "[('play', 1125.0055779957677), ('like', 1019.4936708874717), ('fun', 838.4248903403131), ('free', 835.4917733431378), ('great', 786.3266395204226), ('good', 745.4697690886145), ('ha', 716.4747249752896), ('best', 628.222170064831), ('lot', 586.6488806243898), ('played', 585.5360041471259), ('really', 578.4331036362993), ('time', 550.9211388243643), ('recommend', 539.1841632546433), ('graphic', 480.1785719489129), ('gameplay', 450.2372802849593), ('ive', 438.41669527395646), ('playing', 435.6051594928827), ('just', 435.13191565356743), ('feel', 408.79702874116947), ('friend', 404.3512813394562), ('love', 391.64908605693574), ('new', 384.1338725586336), ('try', 380.8898239464237), ('player', 366.53823598905115), ('pretty', 340.48149393897205), ('different', 339.7610513990076), ('better', 336.81407666591866), ('character', 335.47461877290283), ('thing', 328.1704486807698), ('make', 324.0124771867097), ('amazing', 319.10913770766547), ('community', 318.7548418757696), ('style', 299.9260900320913), ('say', 291.4615995955596), ('bit', 285.0463400747069), ('early', 284.45152675436117), ('access', 277.904396047), ('look', 277.0835570457837), ('highly', 273.7908082358655), ('nice', 272.11979913351723), ('hour', 269.24707424678763), ('experience', 263.4164986944379), ('moba', 263.05908978116446), ('unique', 259.33915076079364), ('ship', 251.0500587404506), ('want', 240.66009110200892), ('enjoy', 239.47306215144593), ('need', 238.4265731486366), ('skill', 234.51567844185465), ('dont', 234.111140903796)]\n",
      "======================================================================\n",
      "[0.2027408  2.12062867 2.19544313 ... 0.20001246 0.20001676 0.20000461]\n",
      "\n",
      "Topic #4:\n",
      "[('tank', 832.0682152479367), ('player', 820.7395628912644), ('just', 777.0318199606105), ('play', 746.4555062257215), ('like', 714.9036884541799), ('time', 706.744933041695), ('ha', 668.5508578682076), ('weapon', 622.6365313957415), ('good', 605.7862784528658), ('dont', 594.8428161576245), ('team', 592.9180686535467), ('make', 572.069910408705), ('want', 522.4702418189472), ('thing', 516.0766741795755), ('money', 507.784589317405), ('wa', 499.62822892236477), ('people', 493.24829893117357), ('new', 488.24814239058117), ('way', 484.2769164893706), ('kill', 478.81909971186343), ('vehicle', 475.8841835294294), ('battle', 468.9257841323647), ('gun', 468.7660819381148), ('point', 457.5102949750885), ('enemy', 450.2307291623959), ('match', 450.19444551050583), ('fun', 428.9252609432959), ('map', 427.6913852571512), ('win', 410.8697409005681), ('pay', 400.5025720946539), ('better', 386.14494807296825), ('plane', 385.4831089892791), ('war', 383.3388434347615), ('really', 381.0637968181364), ('hour', 375.23708248024343), ('playing', 369.98804184300076), ('tier', 362.4968974270817), ('use', 355.9391843025539), ('buy', 344.3965204737421), ('grind', 344.2259717106853), ('need', 323.47184596217903), ('shot', 317.9753199684982), ('lot', 315.66859689856494), ('damage', 310.84314121895824), ('start', 294.05605754563163), ('real', 290.7646430073946), ('year', 289.88114635315543), ('bad', 287.64500812076545), ('long', 283.17554608975223), ('premium', 281.7033931567128)]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each topic,each word of the document is assigned a weight.\n",
    "# Higher weight means it is the top word of the topic.\n",
    "# It is a multidimensional array.Each row represent the topic,each column represents the word in a document.\n",
    "# Shape = [n_topics,n_words] or [n_components, n_features]\n",
    "\n",
    "# Define helper function to print top words for each topic.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        print(topic)\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        print(message)\n",
    "        print([(feature_names[i], topic[i]) for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        # feature_names[i] is a word,topic[i] is the weight of the word for that topic.\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "number_of_words = 50\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = count_vect.get_feature_names()\n",
    "print_top_words(LDA, tf_feature_names, number_of_words)\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9297)\t0.3425246833049525\n",
      "  (0, 18661)\t0.08573368833073064\n",
      "  (0, 2816)\t0.14753762362275624\n",
      "  (0, 8966)\t0.27963845872269194\n",
      "  (0, 7996)\t0.33209505779521536\n",
      "  (0, 13755)\t0.09000125920816517\n",
      "  (0, 18426)\t0.33209505779521536\n",
      "  (0, 18572)\t0.17755586664389592\n",
      "  (0, 1325)\t0.3425246833049525\n",
      "  (0, 8320)\t0.2351464758651997\n",
      "  (0, 796)\t0.1606282261167631\n",
      "  (0, 18389)\t0.1335134519770323\n",
      "  (0, 2953)\t0.16127419418700661\n",
      "  (0, 2358)\t0.10471240034982547\n",
      "  (0, 5516)\t0.13709405694814777\n",
      "  (0, 45)\t0.17755586664389592\n",
      "  (0, 18618)\t0.2841761231572764\n",
      "  (0, 15277)\t0.29542047955612927\n",
      "  (0, 19392)\t0.20878805199845787\n",
      "  (1, 16)\t0.13852512083288648\n",
      "  (1, 3842)\t0.3337102176610715\n",
      "  (1, 11877)\t0.1448339864040923\n",
      "  (1, 11804)\t0.2733004351761694\n",
      "  (1, 3265)\t0.21869967632646073\n",
      "  (1, 4451)\t0.22503297592694574\n",
      "  :\t:\n",
      "  (13994, 1532)\t0.14086247789798925\n",
      "  (13994, 6974)\t0.1366547211499745\n",
      "  (13994, 10803)\t0.12911524767253468\n",
      "  (13994, 5619)\t0.18799404319370158\n",
      "  (13994, 2848)\t0.17367403228416955\n",
      "  (13994, 1949)\t0.08855918278866276\n",
      "  (13994, 5701)\t0.1361487192238249\n",
      "  (13994, 13542)\t0.1080129287070655\n",
      "  (13994, 9627)\t0.08285023699843147\n",
      "  (13994, 13721)\t0.10635454962268495\n",
      "  (13994, 18684)\t0.12541023094741408\n",
      "  (13994, 588)\t0.1162290207410189\n",
      "  (13994, 9922)\t0.0774906719228895\n",
      "  (13994, 11342)\t0.09771893446891086\n",
      "  (13994, 9959)\t0.08907892663657707\n",
      "  (13994, 525)\t0.10635454962268495\n",
      "  (13994, 9788)\t0.101951579180234\n",
      "  (13994, 14939)\t0.08104798433754734\n",
      "  (13994, 19357)\t0.09044975888406194\n",
      "  (13994, 1804)\t0.10348156566860879\n",
      "  (13994, 14859)\t0.10602391022887064\n",
      "  (13994, 10152)\t0.07467900678069897\n",
      "  (13994, 837)\t0.0459418068301555\n",
      "  (13994, 5489)\t0.04650894748952957\n",
      "  (13994, 17490)\t0.048190507353686296\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Topic Modelling : NMF: Non-Matrix factorization.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = tfidf_vect.fit_transform(X_train)\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._nmf.NMF'>\n",
      "[[0.00171902 0.0027099  0.00031854 ... 0.         0.         0.00199683]\n",
      " [0.         0.         0.00044252 ... 0.00990441 0.00315435 0.        ]\n",
      " [0.         0.00081488 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00186065 0.         ... 0.         0.         0.        ]\n",
      " [0.00225753 0.00293271 0.0002522  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "print(type(nmf))\n",
    "nmf.fit(doc_term_matrix)\n",
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model: \n",
      "\n",
      "Topic #0:\n",
      "[('fun', 0.9281842024008672), ('play', 0.8083239228961154), ('great', 0.7745282107161623), ('really', 0.7469751606270683), ('good', 0.7215021616895377), ('like', 0.7168866091663099), ('free', 0.6476114353880471), ('recommend', 0.6410729028072932), ('friend', 0.6088296350687633), ('lot', 0.5761197880546383), ('best', 0.5495056632441343), ('graphic', 0.545972596998205), ('love', 0.5323032329703362), ('played', 0.5319209500998823), ('playing', 0.41864924084202176), ('pretty', 0.41519243811565515), ('try', 0.39260062975277016), ('amazing', 0.3870552553422343), ('nice', 0.37207212472533163), ('feel', 0.3640155034509318), ('ha', 0.363143984671539), ('gameplay', 0.332672896220805), ('ive', 0.3318293033970295), ('character', 0.3283686219637916), ('time', 0.3261920193971382), ('thing', 0.315745145384543), ('bit', 0.30415301691239577), ('better', 0.29865420205090637), ('overall', 0.2804461706572826), ('look', 0.27992350785384684), ('just', 0.27694606684479445), ('world', 0.27621350485474955), ('enjoy', 0.2614685983855151), ('think', 0.25911658796472253), ('easy', 0.2569107673522754), ('little', 0.253125495347178), ('different', 0.24722771077660366), ('highly', 0.24574074771074822), ('awesome', 0.23685884264524742), ('looking', 0.23132401836934), ('style', 0.22127438462646934), ('quite', 0.2199870653610849), ('people', 0.21465118818193665), ('say', 0.21380920813339235), ('fan', 0.2106694919981361), ('worth', 0.20972745737103055), ('far', 0.20922132661492826), ('class', 0.20495534821295378), ('definitely', 0.20416655384699073), ('cool', 0.2036917686452779)]\n",
      "======================================================================\n",
      "\n",
      "Topic #1:\n",
      "[('access', 1.8658147622280625), ('early', 1.8429094819232466), ('reviewthis', 0.65245277505117), ('reviewi', 0.519674291733702), ('pubg', 0.2605470013682722), ('reviewthe', 0.2550394423440077), ('royale', 0.24776977500784658), ('good', 0.24092507126148402), ('wa', 0.20333967944580653), ('like', 0.19923360959983893), ('battle', 0.19320702107762572), ('update', 0.1822089722242983), ('fortnite', 0.1771068485748601), ('fun', 0.17453480719534165), ('reviewits', 0.17010759206499734), ('weapon', 0.16451426117619372), ('alpha', 0.15959225229950866), ('ha', 0.13935909510372907), ('better', 0.13079330160919644), ('ship', 0.12940188615801795), ('play', 0.12613267186452282), ('just', 0.12541305227305985), ('potential', 0.12241540642928758), ('devs', 0.12226821561427255), ('hope', 0.11763238905432788), ('fps', 0.11384868505196125), ('dont', 0.10781305314919888), ('server', 0.10564850290257717), ('smash', 0.10169816701863142), ('gun', 0.10065448131079426), ('csgo', 0.10009661672984453), ('reviewgreat', 0.09922123527652002), ('review', 0.09782537740796074), ('bug', 0.0975163831318832), ('space', 0.09735614462346387), ('great', 0.09687080616546687), ('reviewit', 0.09434603323833904), ('freeearly', 0.0940916251583969), ('br', 0.0921678089377538), ('fix', 0.09205887366124048), ('bros', 0.08657587037385484), ('bad', 0.0862592312075118), ('issue', 0.08623078790584582), ('wait', 0.08604193939558061), ('awesome', 0.08404300388340817), ('really', 0.08386918452505401), ('need', 0.08375297592408186), ('robocraft', 0.0797874413623724), ('reviewvery', 0.0797796886138319), ('movement', 0.07972461164935013)]\n",
      "======================================================================\n",
      "\n",
      "Topic #2:\n",
      "[('card', 1.1431861042491345), ('hearthstone', 0.7373095379719944), ('deck', 0.7287548696410889), ('magic', 0.5135011227522939), ('mtg', 0.40820998680499637), ('gathering', 0.30624644405629414), ('generous', 0.304748809463577), ('mechanic', 0.3030691446572144), ('pack', 0.26700157720417206), ('elder', 0.2634986834482304), ('eternal', 0.25622475082383), ('scroll', 0.25465904335560396), ('mana', 0.2502708912362197), ('ccg', 0.23293859746126439), ('player', 0.2271712018710416), ('mode', 0.2260114973015333), ('digital', 0.2256906201393637), ('reward', 0.22471007385224653), ('f2p', 0.20034740793049063), ('draft', 0.20008660887630597), ('rng', 0.19747388990025264), ('opponent', 0.19593668115570348), ('draw', 0.19178969342680255), ('strategy', 0.18202399718134898), ('ai', 0.18166833265851742), ('arena', 0.17853767059375986), ('easy', 0.1656489081818491), ('story', 0.16411987671284659), ('ranked', 0.16314208950536851), ('build', 0.15527065119075353), ('interesting', 0.15465127424730607), ('turn', 0.15399435311730367), ('best', 0.1532305402781957), ('legend', 0.1531535272168535), ('collection', 0.15202053747721989), ('playing', 0.15157840271990414), ('win', 0.15022259419027828), ('gold', 0.14527906317338465), ('play', 0.1446395263561726), ('ha', 0.14439125658993343), ('meta', 0.14270292941931276), ('played', 0.14031561128134903), ('campaign', 0.13908569853250313), ('like', 0.13297019808960311), ('depth', 0.13219051394822923), ('lot', 0.13140120816988485), ('way', 0.127196808152741), ('power', 0.12601857441036368), ('new', 0.12542249206767847), ('online', 0.11986822940598518)]\n",
      "======================================================================\n",
      "\n",
      "Topic #3:\n",
      "[('pay', 1.1179665015653548), ('money', 1.0208503424436584), ('win', 0.7045216007731523), ('buy', 0.672733980780238), ('real', 0.518111497682086), ('dont', 0.48932161903464083), ('want', 0.4715773197702537), ('spend', 0.44194446272861887), ('free', 0.4225142218320302), ('play', 0.34699003517743715), ('need', 0.3099282250524619), ('just', 0.27800745711387465), ('gun', 0.27728679870346506), ('unless', 0.2763834811474655), ('animal', 0.27500983798171663), ('hunt', 0.24216142177889252), ('hunting', 0.21904084408735372), ('time', 0.21789322352361132), ('paying', 0.2071005866427101), ('fun', 0.20571487653641787), ('unlock', 0.20473535794947503), ('stuff', 0.20409362573536105), ('cost', 0.20167737228199534), ('waste', 0.19472394194188533), ('worth', 0.19318600165934982), ('grind', 0.19112600040123975), ('currency', 0.1885938275755845), ('people', 0.17605941488702778), ('hour', 0.1753662909403145), ('membership', 0.17212094945244905), ('premium', 0.1662975255764313), ('thing', 0.16435380522336354), ('weapon', 0.16116359385505108), ('item', 0.15807813926134), ('spending', 0.1557385771194904), ('deer', 0.15524240511535906), ('ingame', 0.153984082258627), ('good', 0.15116229590854088), ('better', 0.14969282332229336), ('like', 0.14824571978554307), ('cash', 0.1448692529631428), ('really', 0.14480362402603275), ('buying', 0.13544838809012033), ('make', 0.1341242794427244), ('expensive', 0.13384516328777118), ('price', 0.1325019027509879), ('f2p', 0.13156803974614392), ('license', 0.13082797562990747), ('tank', 0.12833318034778854), ('earn', 0.1280192660558061)]\n",
      "======================================================================\n",
      "\n",
      "Topic #4:\n",
      "[('wa', 0.7161230316862348), ('time', 0.5250129549341646), ('just', 0.5181473098674292), ('new', 0.470950677095207), ('player', 0.4570262830560346), ('make', 0.4100359031714534), ('ha', 0.39511395836358504), ('got', 0.3933193322808935), ('im', 0.38874585270764617), ('year', 0.3863287553672294), ('know', 0.37794229101620597), ('hour', 0.3757136316246936), ('people', 0.36769128889888), ('dont', 0.35181932758231166), ('playing', 0.3508774636272295), ('update', 0.35051018596035666), ('way', 0.33674404624542753), ('review', 0.33437461669803636), ('thing', 0.3253363882572148), ('point', 0.31141807624043566), ('bad', 0.3108449197546648), ('long', 0.30696623311077853), ('say', 0.29979632121200606), ('change', 0.2965659339856975), ('server', 0.29366068995200184), ('going', 0.2926041791428886), ('start', 0.29212777760400616), ('did', 0.2898818866541596), ('getting', 0.2858371612261092), ('problem', 0.2855642724842095), ('day', 0.2850312237744153), ('team', 0.2847783468383784), ('used', 0.2743654378188344), ('issue', 0.2725325338410061), ('doesnt', 0.27123251706161616), ('match', 0.26974141303181964), ('minute', 0.26914061226856445), ('come', 0.25332865058110726), ('right', 0.25233746022101927), ('trying', 0.25145577051996715), ('fix', 0.25072706479146023), ('let', 0.2500586242119187), ('didnt', 0.24926974697262283), ('started', 0.2486455964094347), ('making', 0.24704422821332836), ('work', 0.24637715743640579), ('level', 0.24222419314134583), ('reason', 0.24166244072419846), ('devs', 0.24094212659502806), ('actually', 0.2382727929571479)]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# # For each topic,each word of the document is assigned a weight.\n",
    "# # Higher weight means it is the top word of the topic.\n",
    "# # It is a multidimensional array.Each row represent the topic,each column represents the word in a document.\n",
    "# Shape - [n_topics,n_words] or [n_components, n_features].\n",
    "# Factorization matrix.\n",
    "\n",
    "# Define helper function to print top words.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        print(message)\n",
    "        print([(feature_names[i], topic[i]) for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "number_of_words = 50\n",
    "print(\"\\nTopics in NMF model: \")\n",
    "tf_feature_names = tfidf_vect.get_feature_names()  # note that tf_vectorizer is an LemmaCountVectorizer object and with this command we get the whole dictionary of words\n",
    "print_top_words(nmf, tf_feature_names, number_of_words)\n",
    "\n",
    "######################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
