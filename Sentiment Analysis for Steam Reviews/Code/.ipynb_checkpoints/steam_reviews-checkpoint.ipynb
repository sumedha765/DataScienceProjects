{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import string\n",
    "import warnings\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../Data/train.csv\")\n",
    "df_game = pd.read_csv(\"../Data/game_overview.csv\")\n",
    "df_test = pd.read_csv(\"../Data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                        title    year  \\\n",
      "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
      "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
      "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
      "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
      "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
      "\n",
      "                                         user_review  user_suggestion  \n",
      "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
      "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
      "2  A littly iffy on the controls, but once you kn...                1  \n",
      "3  Great game, fun and colorful and all that.A si...                1  \n",
      "4  Not many games have the cute tag right next to...                1  \n",
      "   review_id                             title    year  \\\n",
      "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
      "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
      "2       1605  Counter-Strike: Global Offensive  2018.0   \n",
      "3       1606  Counter-Strike: Global Offensive  2015.0   \n",
      "4       1607  Counter-Strike: Global Offensive  2015.0   \n",
      "\n",
      "                                         user_review  \n",
      "0  Nice graphics, new maps, weapons and models. B...  \n",
      "1  I would not recommend getting into this at its...  \n",
      "2  Edit 11/12/18I have tried playing CS:GO recent...  \n",
      "3  The game is great. But the community is the wo...  \n",
      "4  I thank TrulyRazor for buying this for me a lo...  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows are 17494 .Number of columns is 5\n",
      "Number of rows are 8045 .Number of columns is 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows are\", df_train.shape[0], \".Number of columns is\", df_train.shape[1])\n",
    "print(\"Number of rows are\", df_test.shape[0], \".Number of columns is\", df_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe data types\n",
      "review_id            int64\n",
      "title               object\n",
      "year               float64\n",
      "user_review         object\n",
      "user_suggestion      int64\n",
      "dtype: object\n",
      "review_id        int64\n",
      "title           object\n",
      "year           float64\n",
      "user_review     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Type of each column.Return Object.\n",
    "print(\"Dataframe data types\")\n",
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe column data types\n",
      "Index(['review_id', 'title', 'year', 'user_review', 'user_suggestion'], dtype='object')\n",
      "Index(['review_id', 'title', 'year', 'user_review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Return column names as Index object.\n",
    "print(\"Dataframe column data types\")\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target variable\n",
      "1    9968\n",
      "0    7526\n",
      "Name: user_suggestion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution of target available.\n",
    "print(\"Distribution of target variable\")\n",
    "print(df_train.user_suggestion.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of title variable\n",
      "Robocraft                                             842\n",
      "Eternal Card Game                                     791\n",
      "Heroes & Generals                                     745\n",
      "War Thunder                                           720\n",
      "Fractured Space                                       718\n",
      "Bless Online                                          712\n",
      "The Elder Scrolls®: Legends™                          565\n",
      "Neverwinter                                           546\n",
      "AdventureQuest 3D                                     519\n",
      "theHunter Classic                                     518\n",
      "Creativerse                                           492\n",
      "DCS World Steam Edition                               488\n",
      "Team Fortress 2                                       479\n",
      "Infestation: The New Z                                479\n",
      "PlanetSide 2                                          472\n",
      "Path of Exile                                         458\n",
      "SMITE®                                                454\n",
      "Fallout Shelter                                       447\n",
      "Realm Royale                                          442\n",
      "Trove                                                 430\n",
      "Ring of Elysium                                       419\n",
      "RaceRoom Racing Experience                            416\n",
      "Brawlhalla                                            410\n",
      "Dota 2                                                405\n",
      "Cuisine Royale                                        399\n",
      "Yu-Gi-Oh! Duel Links                                  399\n",
      "Spooky's Jump Scare Mansion                           362\n",
      "Elsword                                               342\n",
      "Realm of the Mad God                                  340\n",
      "World of Tanks Blitz                                  327\n",
      "WARMODE                                               300\n",
      "World of Guns: Gun Disassembly                        293\n",
      "Black Squad                                           288\n",
      "School of Dragons                                     268\n",
      "Bloons TD Battles                                     233\n",
      "Sakura Clicker                                        222\n",
      "Business Tour - Board Game with Online Multiplayer    191\n",
      "Realm Grinder                                         155\n",
      "Crusaders of the Lost Idols                           132\n",
      "EverQuest II                                           69\n",
      "Dreadnought                                            60\n",
      "Freestyle 2: Street Basketball                         57\n",
      "Shop Heroes                                            52\n",
      "Tactical Monsters Rumble Arena                         38\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution of title variable.\n",
    "print(\"Distribution of title variable\")\n",
    "print(df_train.title.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting all letters to lowercase\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting all letters to lowercase\")\n",
    "# Convert text to lowercase.\n",
    "def tolowercase(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(tolowercase)\n",
    "df_test['user_review'] = df_test.user_review.apply(tolowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing punctuation\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing punctuation\")\n",
    "\n",
    "# Remove punctuation.\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(remove_punctuation)\n",
    "df_test['user_review'] = df_test.user_review.apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform lemmatization\n"
     ]
    }
   ],
   "source": [
    "print(\"Perform lemmatization\")\n",
    "\n",
    "# Lemmatization:\n",
    "def do_lemmatization(text):\n",
    "    lemma_words = set([])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = word_tokenize(text)\n",
    "    for word in text:\n",
    "        lemma_words.add(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(do_lemmatization)\n",
    "df_test['user_review'] = df_test.user_review.apply(do_lemmatization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform named entity recognition\n",
      "(S\n",
      "  voice/NN\n",
      "  around/IN\n",
      "  them/PRP\n",
      "  finding/VBG\n",
      "  clean/JJ\n",
      "  bit/NN\n",
      "  return/VB\n",
      "  somewhat/RB\n",
      "  likable/JJ\n",
      "  graphic/JJ\n",
      "  on/IN\n",
      "  kill/NN\n",
      "  see/VBP\n",
      "  in/IN\n",
      "  1990swhat/CD\n",
      "  adorable/JJ\n",
      "  for/IN\n",
      "  hearing/VBG\n",
      "  so/RB\n",
      "  afraid/JJ\n",
      "  calmer/NN\n",
      "  my/PRP$\n",
      "  are/VBP\n",
      "  dead/JJ\n",
      "  but/CC\n",
      "  beat/JJ\n",
      "  few/JJ\n",
      "  ill/JJ\n",
      "  turn/NN\n",
      "  can/MD\n",
      "  before/IN\n",
      "  creepy/JJ\n",
      "  hello/NN\n",
      "  happy/JJ\n",
      "  while/IN\n",
      "  im/NN\n",
      "  with/IN\n",
      "  menever/NN\n",
      "  locked/VBN\n",
      "  such/JJ\n",
      "  review/NN\n",
      "  charactes/NNS\n",
      "  child/VBP\n",
      "  do/VBP\n",
      "  tree/JJ\n",
      "  let/VB\n",
      "  did/VBD\n",
      "  write/VB\n",
      "  were/VBD\n",
      "  pause/RB\n",
      "  been/VBN\n",
      "  asoh/JJ\n",
      "  wait/JJ\n",
      "  heart/NN\n",
      "  bubble/JJ\n",
      "  time/NN\n",
      "  scared/VBD\n",
      "  trying/VBG\n",
      "  ghost/NN\n",
      "  isnot/NN\n",
      "  at/IN\n",
      "  like/IN\n",
      "  that/DT\n",
      "  have/VBP\n",
      "  themor/NN\n",
      "  a/DT\n",
      "  childhood/NN\n",
      "  there/EX\n",
      "  class/NN\n",
      "  is/VBZ\n",
      "  staring/VBG\n",
      "  from/IN\n",
      "  moment/NN\n",
      "  room/NN\n",
      "  more/IN\n",
      "  me/PRP\n",
      "  i/JJ\n",
      "  friend/VBP\n",
      "  look/VBP\n",
      "  full/JJ\n",
      "  shine/NN\n",
      "  of/IN\n",
      "  music/NN\n",
      "  game/NN\n",
      "  to/TO\n",
      "  stand/VB\n",
      "  the/DT\n",
      "  flashlight/JJ\n",
      "  thing/NN\n",
      "  whats/NNS\n",
      "  odd/VBP\n",
      "  door/NN\n",
      "  this/DT\n",
      "  atleast/NN\n",
      "  and/CC\n",
      "  if/IN\n",
      "  chasing/JJ\n",
      "  sceme/NN\n",
      "  hmm/NN\n",
      "  noob/IN\n",
      "  though/IN)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perform named entity recognition\")\n",
    "\n",
    "def named_entity_recognition(text):\n",
    "    result = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    return result\n",
    "\n",
    "text_1 = df_train.user_review[0]\n",
    "ner = named_entity_recognition(text_1)\n",
    "print(ner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of-speech tagging using NLTK\n",
      "0        [(voice, NN), (around, IN), (them, PRP), (find...\n",
      "1        [(game, NN), (to, TO), (computersome, VB), (pa...\n",
      "2        [(highly, RB), (play, JJ), (game, NN), (to, TO...\n",
      "3        [(game, NN), (settle, VB), (to, TO), (yeah, VB...\n",
      "4        [(tag, RB), (close, JJ), (game, NN), (cute, NN...\n",
      "                               ...                        \n",
      "17489    [(warn, NN), (handling, VBG), (well, RB), (one...\n",
      "17490    [(funthe, NN), (evil, JJ), (speed, NN), (would...\n",
      "17491    [(gaming, VBG), (2, CD), (due, JJ), (around, R...\n",
      "17492    [(cool, JJ), (docking, VBG), (game, NN), (only...\n",
      "17493    [(cool, NN), (of, IN), (game, NN), (since, IN)...\n",
      "Name: pos_tagging, Length: 17494, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Part-of-speech tagging using NLTK\")\n",
    "\n",
    "def pos_tagging(text):\n",
    "    text = word_tokenize(text)\n",
    "    tokens_tag = pos_tag(text)\n",
    "    return tokens_tag\n",
    "\n",
    "df_train['pos_tagging'] = df_train.user_review.apply(pos_tagging)\n",
    "print(df_train['pos_tagging'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 15373), ('and', 14988), ('a', 14783), ('game', 14742), ('to', 14639), ('it', 13820), ('is', 12975), ('this', 12317), ('i', 11851), ('you', 11249), ('for', 10447), ('in', 10096), ('that', 9449), ('but', 9128), ('with', 8764)]\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF 15 MOST FREQUENT TERMS.\n",
    "token = nltk.word_tokenize(''.join(df_train.user_review))\n",
    "frequent = nltk.FreqDist(token)\n",
    "print(frequent.most_common(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of word 587\n",
      "\n",
      "Sentence:\n",
      " ['russia natural slavonic believe result october icon ic clothfabrictextile blue hole abduction sergiy greenland it an euro baikal basically acknowledging destroy bowing here bread yosef down human abducted both inside always ha america govt false without but can chamber woodburning service tired most heretic ukraine while healed sin enoch remain now portuguese ruski germany melt mudra vote underneath lower burned do shake through secret drunk airplane discovered preach those other blasphemer twisted need groin fake each energy care eurasia eldeity pacific church like disagree red there nail planetary tube hit will side satanist trench under country alaska azazel statue bacteriologist clergy metal grow triple water during chinese since mountain level wont another mendel logic hide his cortes this weapon prayer crossing and pelageya diamond whole 8th bug take run creator into anathema muslim depicted reject bird youll good bunch your left inland airspace swallow fall month eat himself war skin hand foot stop them holy filling zero collapse tsar crowning synthetic fully chest either siberia 2nd elijah ww3 antarctica belief use aggression nerve seraph instead participate same radonezh appear put before few youre shoulder pale cut earth get iv administered want very hebrew saint scandinavia abduct devil show buddhist first their thru celcius superpower chanted robe bigger out fast 11th behind sample live soldier scientist normal that over way sionists crowned 4in religion switch conquers a dusha curse satan israeli power order main they alien more new allows quiet super unmeltable gaad eye 4 finger wound prison read five etc correctly off except exhibit river after ago planet roman not about repeatedly attack when cross trait creation also betraying vyacheslav stadiumsize passion pole save week liberty people u if 1st incorrectly resurrected shovel council 3in against body priest flat sleep ocean tibet last between hexagram him word catholic never fly alexandre return freeze santa long cell sarov in vaccine deceived surrounded happens thought pray big fear then past dont bishop demon mercy clothes bubonic transfer god 3 are my designed stay weather make together what possessed our stripper with learn rico leader 2inside mariana inviting infirmitiesillnessessicknesses created orthodoxy signed flag invite across costume fetus higher zodiac come high time fuel horoscope step move serve spirit jew biggest sky knife stick atlantis at pay yersin inspired have 200 because keep wa nanochips longer ufo all lot schneerson from 1066 krasheninnikov light orthodox go tell clothed predicted nato clothing xc kelvin craft 7 crowbar june aborted 12 nika stranded sold only italian abyss closet leg rocket image sign sometimes chunk shroud patriarch head away who menachem clone holiday forward 10001500 right slowly earthquake guardian ural radiation crucified done up satanic china pose short ryazan which 2 3rd wolf meeting kneeling blasphemy old one 666 proper killed symbol upside antichrist he showing 2006 plague on kill wanted see taken trapped blame temple standing communion meet isi or for american so glove back tectonic worship pillar plate no medicine lake food elect angel oh christian dna iran blood zombie let base be just sinkhole were poison volga dream medical 7525 saying 1moon dy spanish being cant life 666ed disease maya allegiance wear 1km prophet doesnt nuke kailash 36 biogenetic per bring nine used 8 these is intelligence blow bomb world person megatsunamis next hurry plus ice document where look 2016 hence fight german stove supreme nobody of three turkey to stand the trinity you cover panic rejecting others than language coast ad milan third commonly massive lenin christ try soul say dinosaur turin surround implant provides giant jesus many year by']\n"
     ]
    }
   ],
   "source": [
    "# Text with highest number of words.\n",
    "df_train['number_of_words'] = df_train['user_review'].apply(lambda x: len(str(x).split()))\n",
    "print('Maximum number of word',df_train['number_of_words'].max())\n",
    "print('\\nSentence:\\n',df_train[df_train['number_of_words'] == 587]['user_review'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995,)\n",
      "(3499,)\n",
      "(13995,)\n",
      "(3499,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train['user_review']\n",
    "y = df_train['user_suggestion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(13995, 5000)\n",
      "(3499, 5000)\n",
      "(8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "# # Feature Extraction using TFIDF-Char Based.\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), stop_words='english', analyzer='char',max_features=5000)\n",
    "print(type(tfidf_vec))  # TfidfVectorizer class.\n",
    "train_tfidf_vec = tfidf_vec.fit_transform(X_train)\n",
    "print(type(train_tfidf_vec))  # Sparse CSR matrix.\n",
    "valid_tfidf_vec = tfidf_vec.transform(X_test)\n",
    "print(type(valid_tfidf_vec))  # Sparse CSR matrix.\n",
    "test_tfidf_vec = tfidf_vec.transform(df_test['user_review'])\n",
    "train_vector_array = train_tfidf_vec.toarray()\n",
    "valid_vector_array = valid_tfidf_vec.toarray()\n",
    "test_vector_array = test_tfidf_vec.toarray()\n",
    "\n",
    "print(train_vector_array.shape)\n",
    "print(valid_vector_array.shape)\n",
    "print(test_vector_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8288082309231207\n"
     ]
    }
   ],
   "source": [
    "# Linear support vector classifier.\n",
    "lsvc = LinearSVC(C=1,loss= 'hinge',random_state=999)\n",
    "lsvc.fit(train_vector_array, y_train)\n",
    "y_pred = lsvc.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))   # 0.8250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8136610460131466\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression.\n",
    "lr = LogisticRegression(random_state=999)\n",
    "lr.fit(train_vector_array, y_train)\n",
    "y_pred = lr.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.8128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8246225319396052\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier.\n",
    "rfc = RandomForestClassifier(n_estimators=300, random_state=999)\n",
    "rfc.fit(train_vector_array, y_train)\n",
    "pred = rfc.predict(valid_vector_array)\n",
    "print(f1_score(y_test, pred))  # 0.8270\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6516147470705916\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes.\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(train_vector_array,y_train)\n",
    "y_pred = bnb.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.6547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8353815375821664\n"
     ]
    }
   ],
   "source": [
    "# Ridge Classifier.\n",
    "ridge = RidgeClassifier(random_state=999)\n",
    "ridge.fit(train_vector_array,y_train)\n",
    "y_pred = ridge.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.8348\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_final = ridge.predict((test_vector_array))\n",
    "df = pd.DataFrame({'review_id': df_test['review_id'], 'user_suggestion': pred_final})\n",
    "df.to_csv(\"submission_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7996)\t1\n",
      "  (0, 18389)\t1\n",
      "  (0, 1325)\t1\n",
      "  (0, 18572)\t1\n",
      "  (0, 18661)\t1\n",
      "  (0, 15277)\t1\n",
      "  (0, 9297)\t1\n",
      "  (0, 2953)\t1\n",
      "  (0, 18618)\t1\n",
      "  (0, 19392)\t1\n",
      "  (0, 2816)\t1\n",
      "  (0, 8320)\t1\n",
      "  (0, 18426)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 796)\t1\n",
      "  (0, 8966)\t1\n",
      "  (0, 2358)\t1\n",
      "  (0, 5516)\t1\n",
      "  (0, 13755)\t1\n",
      "  (1, 13256)\t1\n",
      "  (1, 18617)\t1\n",
      "  (1, 12757)\t1\n",
      "  (1, 6905)\t1\n",
      "  (1, 3265)\t1\n",
      "  (1, 11804)\t1\n",
      "  :\t:\n",
      "  (13994, 1949)\t1\n",
      "  (13994, 5619)\t1\n",
      "  (13994, 10803)\t1\n",
      "  (13994, 6974)\t1\n",
      "  (13994, 1532)\t1\n",
      "  (13994, 16951)\t1\n",
      "  (13994, 16978)\t1\n",
      "  (13994, 12286)\t1\n",
      "  (13994, 16455)\t1\n",
      "  (13994, 8247)\t1\n",
      "  (13994, 14371)\t1\n",
      "  (13994, 7565)\t1\n",
      "  (13994, 12703)\t1\n",
      "  (13994, 11531)\t1\n",
      "  (13994, 19458)\t1\n",
      "  (13994, 10333)\t1\n",
      "  (13994, 19408)\t1\n",
      "  (13994, 15822)\t1\n",
      "  (13994, 11806)\t1\n",
      "  (13994, 13418)\t1\n",
      "  (13994, 19409)\t1\n",
      "  (13994, 16924)\t1\n",
      "  (13994, 4395)\t1\n",
      "  (13994, 4024)\t1\n",
      "  (13994, 15697)\t1\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# LDA Topic Modelling:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(X_train)\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._lda.LatentDirichletAllocation'>\n",
      "[[1.50392197 0.20285865 0.20000048 ... 0.20001073 0.20001242 0.20000421]\n",
      " [2.22030621 9.26054728 0.20059775 ... 0.2019053  1.19880946 4.19996877]\n",
      " [0.2029754  0.20583334 0.20000148 ... 0.20003713 0.2000419  0.20001373]\n",
      " [1.87005562 0.21013206 0.20395717 ... 2.19803437 1.20111946 0.20000869]\n",
      " [0.2027408  2.12062867 2.19544313 ... 0.20001246 0.20001676 0.20000461]]\n"
     ]
    }
   ],
   "source": [
    "# Each of x documents is represented as y dimensional vector,which means that our vocabulary has y words.\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "LDA = LatentDirichletAllocation(n_components=5,\n",
    "                                random_state=0)\n",
    "print(type(LDA))  # LatentDirichletAllocation class.\n",
    "LDA.fit(doc_term_matrix)\n",
    "print(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "[1.50392197 0.20285865 0.20000048 ... 0.20001073 0.20001242 0.20000421]\n",
      "\n",
      "Topic #0:\n",
      "[('just', 1246.2293574901796), ('play', 1238.202823321897), ('like', 1233.0199735780066), ('money', 1164.457799059524), ('time', 1160.5062199639851), ('dont', 1113.8961971124834), ('pay', 982.8027046425121), ('fun', 982.7455095978111), ('free', 955.6708150453078), ('want', 938.6225372268863), ('buy', 835.6175458444802), ('really', 808.7895968052721), ('make', 800.7320921994638), ('good', 777.9739181608671), ('thing', 761.2893860360759), ('need', 755.7732242094681), ('playing', 714.0867502575807), ('real', 693.6838553295984), ('people', 682.5548089004271), ('hour', 677.0993088320332), ('spend', 635.736283731464), ('way', 617.0253866954564), ('lot', 612.7801510685354), ('player', 607.747791429377), ('ha', 606.5678635337347), ('level', 577.0491998010373), ('new', 560.4528272964557), ('item', 543.9535131112627), ('win', 540.9006571508393), ('youre', 499.73615730924075), ('great', 474.1922716557834), ('character', 473.72227898802964), ('pretty', 459.56474302760427), ('wa', 453.3193962385893), ('use', 438.08514163653115), ('better', 437.6988464293973), ('think', 437.2891172050655), ('feel', 428.24613335070995), ('try', 421.8940934698756), ('best', 414.2831276975314), ('know', 409.6487143309186), ('worth', 407.1492414865633), ('stuff', 405.776656923492), ('recommend', 397.13591329667264), ('thats', 394.51729369027174), ('say', 372.9730237899088), ('start', 368.3928749782196), ('played', 365.42266433055045), ('quest', 363.47243198138716), ('im', 362.408951621669)]\n",
      "======================================================================\n",
      "[2.22030621 9.26054728 0.20059775 ... 0.2019053  1.19880946 4.19996877]\n",
      "\n",
      "Topic #1:\n",
      "[('access', 4028.915499044034), ('early', 3885.650418285518), ('just', 2262.0405358038965), ('like', 2257.8234760265673), ('wa', 2220.652016168195), ('play', 2213.6348992641647), ('dont', 1736.5758658484226), ('time', 1733.2710317105027), ('good', 1701.948733695616), ('fun', 1467.9829184200032), ('ha', 1391.513939404435), ('really', 1282.5314858133809), ('make', 1203.4945738526837), ('playing', 1175.5708096638145), ('played', 1093.0370175160733), ('people', 1040.1329804895145), ('thing', 1021.1396518470331), ('im', 949.8531701333211), ('new', 934.5318106332682), ('got', 918.3328700510958), ('bad', 892.6942668731167), ('hour', 864.1279998059927), ('better', 853.1558985322968), ('say', 848.4885699047029), ('great', 842.3239649054549), ('player', 838.3155338177431), ('update', 825.0504474613444), ('know', 779.625625013713), ('want', 747.4782999144018), ('free', 714.9271609804093), ('need', 713.7354363545786), ('review', 712.6141119798615), ('server', 704.2095851655093), ('way', 643.3092368931999), ('think', 628.5809420602591), ('lot', 622.3466372476903), ('year', 616.1384514692068), ('recommend', 606.7388979285424), ('love', 585.2199813282737), ('reviewi', 584.7351287674352), ('reviewthis', 584.6905452043433), ('day', 584.0970244048514), ('try', 574.1739701473842), ('look', 566.7903653363641), ('feel', 564.9310238505328), ('friend', 562.5630320554402), ('ive', 558.6745743429326), ('steam', 554.0127432893522), ('money', 552.9055513706415), ('going', 537.4627864944111)]\n",
      "======================================================================\n",
      "[0.2029754  0.20583334 0.20000148 ... 0.20003713 0.2000419  0.20001373]\n",
      "\n",
      "Topic #2:\n",
      "[('card', 911.4493892719934), ('early', 551.0706265470055), ('deck', 542.508864108446), ('access', 536.274442333431), ('hearthstone', 426.68160813089486), ('play', 398.7011931922899), ('time', 330.5566764592962), ('magic', 305.18340074222596), ('like', 278.759191053611), ('ha', 254.89261421817812), ('player', 224.65887587241184), ('just', 215.56637109159013), ('played', 211.5498772888689), ('mtg', 210.09220296494516), ('mechanic', 208.12705003434962), ('make', 198.69094635228072), ('turn', 196.01012458083022), ('way', 185.60363114280742), ('opponent', 180.79491503549016), ('wa', 174.96382312700277), ('playing', 172.74923874256402), ('mobile', 165.72483635717333), ('draw', 158.15413890465476), ('mana', 155.1286851460897), ('mode', 154.35155143545788), ('fun', 148.92142069842077), ('good', 148.82130060188578), ('eternal', 147.08843788177992), ('dont', 146.5739799775145), ('gathering', 142.78658341670305), ('win', 141.41308671299493), ('generous', 141.29223038256495), ('scroll', 139.7242968436157), ('doesnt', 137.7113498079064), ('free', 133.42981607179001), ('ive', 133.40059785402931), ('pack', 132.2424867332088), ('elder', 131.03830066757044), ('really', 129.18201692675962), ('reward', 127.56456880980163), ('rng', 123.51901628468156), ('digital', 120.49941595460119), ('ccg', 120.34548805968235), ('great', 118.76805499038069), ('yugioh', 118.76552133500194), ('ai', 118.24795348507423), ('lot', 117.5557341606698), ('start', 115.1524383501914), ('set', 113.6247472130823), ('im', 112.50867234040051)]\n",
      "======================================================================\n",
      "[1.87005562 0.21013206 0.20395717 ... 2.19803437 1.20111946 0.20000869]\n",
      "\n",
      "Topic #3:\n",
      "[('play', 1125.005577995768), ('like', 1019.4936708874709), ('fun', 838.4248903403111), ('free', 835.4917733431364), ('great', 786.3266395204225), ('good', 745.4697690886143), ('ha', 716.4747249752892), ('best', 628.2221700648298), ('lot', 586.6488806243892), ('played', 585.5360041471268), ('really', 578.4331036362993), ('time', 550.9211388243654), ('recommend', 539.1841632546434), ('graphic', 480.1785719489124), ('gameplay', 450.2372802849593), ('ive', 438.4166952739566), ('playing', 435.60515949288475), ('just', 435.1319156535674), ('feel', 408.7970287411703), ('friend', 404.3512813394566), ('love', 391.6490860569361), ('new', 384.1338725586345), ('try', 380.88982394642403), ('player', 366.53823598905154), ('pretty', 340.4814939389713), ('different', 339.7610513990073), ('better', 336.8140766659192), ('character', 335.4746187729036), ('thing', 328.1704486807695), ('make', 324.01247718671016), ('amazing', 319.1091377076648), ('community', 318.7548418757692), ('style', 299.9260900320915), ('say', 291.4615995955598), ('bit', 285.04634007470685), ('early', 284.4515267543618), ('access', 277.90439604700094), ('look', 277.08355704578304), ('highly', 273.790808235865), ('nice', 272.1197991335169), ('hour', 269.2470742467882), ('experience', 263.4164986944382), ('moba', 263.05908978116497), ('unique', 259.3391507607941), ('ship', 251.05005874045014), ('want', 240.66009110200918), ('enjoy', 239.47306215144607), ('need', 238.4265731486365), ('skill', 234.51567844185504), ('dont', 234.11114090379624)]\n",
      "======================================================================\n",
      "[0.2027408  2.12062867 2.19544313 ... 0.20001246 0.20001676 0.20000461]\n",
      "\n",
      "Topic #4:\n",
      "[('tank', 832.0682152479369), ('player', 820.7395628912682), ('just', 777.0318199606138), ('play', 746.4555062257251), ('like', 714.9036884541844), ('time', 706.7449330416986), ('ha', 668.5508578682114), ('weapon', 622.636531395744), ('good', 605.7862784528692), ('dont', 594.8428161576263), ('team', 592.918068653548), ('make', 572.069910408707), ('want', 522.4702418189494), ('thing', 516.0766741795774), ('money', 507.7845893174066), ('wa', 499.628228922367), ('people', 493.2482989311761), ('new', 488.24814239058327), ('way', 484.2769164893732), ('kill', 478.8190997118649), ('vehicle', 475.8841835294295), ('battle', 468.9257841323659), ('gun', 468.7660819381157), ('point', 457.51029497509074), ('enemy', 450.2307291623969), ('match', 450.19444551050714), ('fun', 428.92526094329804), ('map', 427.69138525715255), ('win', 410.86974090056935), ('pay', 400.5025720946552), ('better', 386.14494807297024), ('plane', 385.48310898927923), ('war', 383.3388434347623), ('really', 381.06379681813814), ('hour', 375.2370824802452), ('playing', 369.9880418430028), ('tier', 362.496897427082), ('use', 355.9391843025547), ('buy', 344.39652047374403), ('grind', 344.22597171068645), ('need', 323.47184596218034), ('shot', 317.97531996849847), ('lot', 315.6685968985662), ('damage', 310.84314121895954), ('start', 294.056057545633), ('real', 290.76464300739576), ('year', 289.8811463531566), ('bad', 287.6450081207663), ('long', 283.1755460897531), ('premium', 281.70339315671356)]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each topic,each word of the document is assigned a weight.\n",
    "# Higher weight means it is the top word of the topic.\n",
    "# It is a multidimensional array.Each row represent the topic,each column represents the word in a document.\n",
    "# Shape = [n_topics,n_words] or [n_components, n_features]\n",
    "\n",
    "# Define helper function to print top words for each topic.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        print(topic)\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        print(message)\n",
    "        print([(feature_names[i], topic[i]) for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        # feature_names[i] is a word,topic[i] is the weight of the word for that topic.\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "number_of_words = 50\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = count_vect.get_feature_names()\n",
    "print_top_words(LDA, tf_feature_names, number_of_words)\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13755)\t0.09000125920816518\n",
      "  (0, 5516)\t0.1370940569481478\n",
      "  (0, 2358)\t0.10471240034982549\n",
      "  (0, 8966)\t0.279638458722692\n",
      "  (0, 796)\t0.16062822611676314\n",
      "  (0, 45)\t0.17755586664389594\n",
      "  (0, 18426)\t0.33209505779521536\n",
      "  (0, 8320)\t0.23514647586519974\n",
      "  (0, 2816)\t0.14753762362275627\n",
      "  (0, 19392)\t0.2087880519984579\n",
      "  (0, 18618)\t0.2841761231572764\n",
      "  (0, 2953)\t0.16127419418700664\n",
      "  (0, 9297)\t0.34252468330495256\n",
      "  (0, 15277)\t0.2954204795561293\n",
      "  (0, 18661)\t0.08573368833073065\n",
      "  (0, 18572)\t0.17755586664389594\n",
      "  (0, 1325)\t0.34252468330495256\n",
      "  (0, 18389)\t0.1335134519770323\n",
      "  (0, 7996)\t0.33209505779521536\n",
      "  (1, 8031)\t0.19047254451303194\n",
      "  (1, 9062)\t0.2936874184273153\n",
      "  (1, 12065)\t0.17570132013706943\n",
      "  (1, 7055)\t0.08330922032821561\n",
      "  (1, 12227)\t0.23889339481759647\n",
      "  (1, 3842)\t0.33371021766107156\n",
      "  :\t:\n",
      "  (13994, 1532)\t0.14086247789798925\n",
      "  (13994, 6974)\t0.1366547211499745\n",
      "  (13994, 10803)\t0.12911524767253468\n",
      "  (13994, 5619)\t0.18799404319370158\n",
      "  (13994, 1949)\t0.08855918278866276\n",
      "  (13994, 2848)\t0.17367403228416955\n",
      "  (13994, 5701)\t0.1361487192238249\n",
      "  (13994, 13542)\t0.1080129287070655\n",
      "  (13994, 13721)\t0.10635454962268495\n",
      "  (13994, 9627)\t0.08285023699843147\n",
      "  (13994, 18684)\t0.12541023094741408\n",
      "  (13994, 588)\t0.1162290207410189\n",
      "  (13994, 9922)\t0.0774906719228895\n",
      "  (13994, 11342)\t0.09771893446891086\n",
      "  (13994, 525)\t0.10635454962268495\n",
      "  (13994, 9959)\t0.08907892663657707\n",
      "  (13994, 19357)\t0.09044975888406194\n",
      "  (13994, 14939)\t0.08104798433754734\n",
      "  (13994, 9788)\t0.101951579180234\n",
      "  (13994, 1804)\t0.10348156566860879\n",
      "  (13994, 14859)\t0.10602391022887064\n",
      "  (13994, 10152)\t0.07467900678069897\n",
      "  (13994, 5489)\t0.04650894748952957\n",
      "  (13994, 837)\t0.0459418068301555\n",
      "  (13994, 17490)\t0.048190507353686296\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Topic Modelling : NMF: Non-Matrix factorization.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = tfidf_vect.fit_transform(X_train)\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._nmf.NMF'>\n",
      "[[0.00171902 0.0027099  0.00031854 ... 0.         0.         0.00199683]\n",
      " [0.         0.         0.00044252 ... 0.00990441 0.00315435 0.        ]\n",
      " [0.         0.00081488 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00186065 0.         ... 0.         0.         0.        ]\n",
      " [0.00225753 0.00293271 0.0002522  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "print(type(nmf))\n",
    "nmf.fit(doc_term_matrix)\n",
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model: \n",
      "\n",
      "Topic #0:\n",
      "[('fun', 0.9281842024008746), ('play', 0.8083239228961205), ('great', 0.7745282107161673), ('really', 0.7469751606270727), ('good', 0.721502161689542), ('like', 0.716886609166314), ('free', 0.6476114353880519), ('recommend', 0.6410729028072987), ('friend', 0.6088296350687681), ('lot', 0.5761197880546413), ('best', 0.5495056632441386), ('graphic', 0.5459725969982085), ('love', 0.5323032329703404), ('played', 0.5319209500998867), ('playing', 0.4186492408420255), ('pretty', 0.4151924381156579), ('try', 0.3926006297527731), ('amazing', 0.3870552553422373), ('nice', 0.37207212472533385), ('feel', 0.3640155034509345), ('ha', 0.3631439846715412), ('gameplay', 0.33267289622080687), ('ive', 0.3318293033970323), ('character', 0.328368621963794), ('time', 0.32619201939714104), ('thing', 0.3157451453845452), ('bit', 0.3041530169123975), ('better', 0.2986542020509087), ('overall', 0.2804461706572846), ('look', 0.27992350785384845), ('just', 0.2769460668447968), ('world', 0.27621350485475143), ('enjoy', 0.26146859838551684), ('think', 0.2591165879647243), ('easy', 0.2569107673522772), ('little', 0.25312549534717943), ('different', 0.24722771077660524), ('highly', 0.2457407477107496), ('awesome', 0.23685884264524937), ('looking', 0.23132401836934108), ('style', 0.22127438462647075), ('quite', 0.2199870653610865), ('people', 0.21465118818193776), ('say', 0.21380920813339374), ('fan', 0.2106694919981376), ('worth', 0.20972745737103232), ('far', 0.20922132661492981), ('class', 0.2049553482129553), ('definitely', 0.20416655384699198), ('cool', 0.20369176864527938)]\n",
      "======================================================================\n",
      "\n",
      "Topic #1:\n",
      "[('access', 1.8658147622280785), ('early', 1.8429094819232608), ('reviewthis', 0.6524527750511757), ('reviewi', 0.519674291733706), ('pubg', 0.2605470013682745), ('reviewthe', 0.2550394423440096), ('royale', 0.2477697750078485), ('good', 0.24092507126148574), ('wa', 0.2033396794458082), ('like', 0.19923360959983918), ('battle', 0.19320702107762724), ('update', 0.1822089722242999), ('fortnite', 0.17710684857486142), ('fun', 0.1745348071953421), ('reviewits', 0.17010759206499876), ('weapon', 0.16451426117619503), ('alpha', 0.15959225229950982), ('ha', 0.13935909510373035), ('better', 0.1307933016091972), ('ship', 0.12940188615801906), ('play', 0.12613267186452284), ('just', 0.1254130522730606), ('potential', 0.1224154064292886), ('devs', 0.12226821561427355), ('hope', 0.11763238905432849), ('fps', 0.11384868505196222), ('dont', 0.1078130531492), ('server', 0.10564850290257811), ('smash', 0.10169816701863227), ('gun', 0.10065448131079532), ('csgo', 0.10009661672984531), ('reviewgreat', 0.09922123527652084), ('review', 0.09782537740796146), ('bug', 0.09751638313188393), ('space', 0.09735614462346458), ('great', 0.09687080616546803), ('reviewit', 0.09434603323833979), ('freeearly', 0.09409162515839764), ('br', 0.0921678089377545), ('fix', 0.09205887366124064), ('bros', 0.08657587037385561), ('bad', 0.08625923120751211), ('issue', 0.08623078790584618), ('wait', 0.0860419393955814), ('awesome', 0.08404300388340864), ('really', 0.08386918452505401), ('need', 0.08375297592408215), ('robocraft', 0.07978744136237308), ('reviewvery', 0.07977968861383258), ('movement', 0.07972461164935078)]\n",
      "======================================================================\n",
      "\n",
      "Topic #2:\n",
      "[('card', 1.1431861042491342), ('hearthstone', 0.7373095379719944), ('deck', 0.7287548696410892), ('magic', 0.5135011227522939), ('mtg', 0.40820998680499637), ('gathering', 0.3062464440562941), ('generous', 0.304748809463577), ('mechanic', 0.3030691446572145), ('pack', 0.267001577204172), ('elder', 0.2634986834482304), ('eternal', 0.25622475082383), ('scroll', 0.254659043355604), ('mana', 0.25027089123621965), ('ccg', 0.23293859746126436), ('player', 0.22717120187104145), ('mode', 0.2260114973015332), ('digital', 0.22569062013936367), ('reward', 0.2247100738522466), ('f2p', 0.20034740793049058), ('draft', 0.20008660887630594), ('rng', 0.1974738899002526), ('opponent', 0.19593668115570348), ('draw', 0.19178969342680252), ('strategy', 0.18202399718134893), ('ai', 0.1816683326585173), ('arena', 0.17853767059375983), ('easy', 0.16564890818184916), ('story', 0.16411987671284659), ('ranked', 0.16314208950536854), ('build', 0.15527065119075353), ('interesting', 0.154651274247306), ('turn', 0.1539943531173036), ('best', 0.15323054027819547), ('legend', 0.15315352721685352), ('collection', 0.15202053747721989), ('playing', 0.15157840271990422), ('win', 0.1502225941902782), ('gold', 0.14527906317338463), ('play', 0.1446395263561725), ('ha', 0.14439125658993335), ('meta', 0.14270292941931279), ('played', 0.14031561128134898), ('campaign', 0.13908569853250316), ('like', 0.13297019808960298), ('depth', 0.13219051394822914), ('lot', 0.13140120816988493), ('way', 0.12719680815274098), ('power', 0.12601857441036368), ('new', 0.12542249206767847), ('online', 0.11986822940598518)]\n",
      "======================================================================\n",
      "\n",
      "Topic #3:\n",
      "[('pay', 1.1179665015653588), ('money', 1.0208503424436628), ('win', 0.7045216007731544), ('buy', 0.6727339807802409), ('real', 0.518111497682088), ('dont', 0.4893216190346428), ('want', 0.47157731977025547), ('spend', 0.4419444627286207), ('free', 0.42251422183203163), ('play', 0.34699003517743954), ('need', 0.30992822505246276), ('just', 0.2780074571138757), ('gun', 0.2772867987034664), ('unless', 0.27638348114746697), ('animal', 0.27500983798171774), ('hunt', 0.2421614217788934), ('hunting', 0.21904084408735455), ('time', 0.217893223523612), ('paying', 0.20710058664271097), ('fun', 0.2057148765364186), ('unlock', 0.20473535794947573), ('stuff', 0.20409362573536194), ('cost', 0.20167737228199614), ('waste', 0.19472394194188603), ('worth', 0.19318600165935046), ('grind', 0.19112600040124045), ('currency', 0.18859382757558538), ('people', 0.1760594148870284), ('hour', 0.17536629094031508), ('membership', 0.17212094945244982), ('premium', 0.1662975255764321), ('thing', 0.16435380522336435), ('weapon', 0.1611635938550515), ('item', 0.15807813926134065), ('spending', 0.15573857711949107), ('deer', 0.1552424051153597), ('ingame', 0.15398408225862742), ('good', 0.15116229590854172), ('better', 0.14969282332229444), ('like', 0.1482457197855435), ('cash', 0.14486925296314332), ('really', 0.14480362402603278), ('buying', 0.13544838809012086), ('make', 0.1341242794427243), ('expensive', 0.1338451632877716), ('price', 0.13250190275098847), ('f2p', 0.13156803974614445), ('license', 0.13082797562990792), ('tank', 0.12833318034778926), ('earn', 0.12801926605580655)]\n",
      "======================================================================\n",
      "\n",
      "Topic #4:\n",
      "[('wa', 0.7161230316862431), ('time', 0.5250129549341688), ('just', 0.518147309867435), ('new', 0.4709506770952122), ('player', 0.4570262830560395), ('make', 0.4100359031714591), ('ha', 0.3951139583635897), ('got', 0.39331933228089855), ('im', 0.3887458527076505), ('year', 0.38632875536723293), ('know', 0.3779422910162105), ('hour', 0.3757136316246985), ('people', 0.3676912888988851), ('dont', 0.3518193275823157), ('playing', 0.3508774636272329), ('update', 0.35051018596036077), ('way', 0.3367440462454315), ('review', 0.3343746166980402), ('thing', 0.3253363882572182), ('point', 0.31141807624043877), ('bad', 0.3108449197546682), ('long', 0.30696623311078297), ('say', 0.2997963212120096), ('change', 0.2965659339857005), ('server', 0.2936606899520047), ('going', 0.292604179142892), ('start', 0.2921277776040094), ('did', 0.28988188665416253), ('getting', 0.2858371612261122), ('problem', 0.28556427248421246), ('day', 0.2850312237744186), ('team', 0.28477834683838166), ('used', 0.2743654378188375), ('issue', 0.272532533841009), ('doesnt', 0.2712325170616198), ('match', 0.2697414130318234), ('minute', 0.26914061226856734), ('come', 0.25332865058111037), ('right', 0.25233746022102205), ('trying', 0.25145577051997003), ('fix', 0.2507270647914636), ('let', 0.25005862421192165), ('didnt', 0.24926974697262563), ('started', 0.2486455964094373), ('making', 0.2470442282133311), ('work', 0.2463771574364087), ('level', 0.2422241931413488), ('reason', 0.24166244072420132), ('devs', 0.24094212659503067), ('actually', 0.23827279295715062)]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# # For each topic,each word of the document is assigned a weight.\n",
    "# # Higher weight means it is the top word of the topic.\n",
    "# # It is a multidimensional array.Each row represent the topic,each column represents the word in a document.\n",
    "# Shape - [n_topics,n_words] or [n_components, n_features].\n",
    "# Factorization matrix.\n",
    "\n",
    "# Define helper function to print top words.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        print(message)\n",
    "        print([(feature_names[i], topic[i]) for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "number_of_words = 50\n",
    "print(\"\\nTopics in NMF model: \")\n",
    "tf_feature_names = tfidf_vect.get_feature_names()  # note that tf_vectorizer is an LemmaCountVectorizer object and with this command we get the whole dictionary of words\n",
    "print_top_words(nmf, tf_feature_names, number_of_words)\n",
    "\n",
    "######################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
