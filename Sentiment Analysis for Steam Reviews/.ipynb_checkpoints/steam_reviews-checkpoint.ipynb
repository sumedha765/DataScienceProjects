{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "import string\n",
    "import warnings\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data/train.csv\")\n",
    "df_game = pd.read_csv(\"Data/game_overview.csv\")\n",
    "df_test = pd.read_csv(\"Data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                        title    year  \\\n",
      "0          1  Spooky's Jump Scare Mansion  2016.0   \n",
      "1          2  Spooky's Jump Scare Mansion  2016.0   \n",
      "2          3  Spooky's Jump Scare Mansion  2016.0   \n",
      "3          4  Spooky's Jump Scare Mansion  2015.0   \n",
      "4          5  Spooky's Jump Scare Mansion  2015.0   \n",
      "\n",
      "                                         user_review  user_suggestion  \n",
      "0  I'm scared and hearing creepy voices.  So I'll...                1  \n",
      "1  Best game, more better than Sam Pepper's YouTu...                1  \n",
      "2  A littly iffy on the controls, but once you kn...                1  \n",
      "3  Great game, fun and colorful and all that.A si...                1  \n",
      "4  Not many games have the cute tag right next to...                1  \n",
      "   review_id                             title    year  \\\n",
      "0       1603  Counter-Strike: Global Offensive  2015.0   \n",
      "1       1604  Counter-Strike: Global Offensive  2018.0   \n",
      "2       1605  Counter-Strike: Global Offensive  2018.0   \n",
      "3       1606  Counter-Strike: Global Offensive  2015.0   \n",
      "4       1607  Counter-Strike: Global Offensive  2015.0   \n",
      "\n",
      "                                         user_review  \n",
      "0  Nice graphics, new maps, weapons and models. B...  \n",
      "1  I would not recommend getting into this at its...  \n",
      "2  Edit 11/12/18I have tried playing CS:GO recent...  \n",
      "3  The game is great. But the community is the wo...  \n",
      "4  I thank TrulyRazor for buying this for me a lo...  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows are 17494 .Number of columns is 5\n",
      "Number of rows are 8045 .Number of columns is 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows are\", df_train.shape[0], \".Number of columns is\", df_train.shape[1])\n",
    "print(\"Number of rows are\", df_test.shape[0], \".Number of columns is\", df_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe data types\n",
      "review_id            int64\n",
      "title               object\n",
      "year               float64\n",
      "user_review         object\n",
      "user_suggestion      int64\n",
      "dtype: object\n",
      "review_id        int64\n",
      "title           object\n",
      "year           float64\n",
      "user_review     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Type of each column.Return Object.\n",
    "print(\"Dataframe data types\")\n",
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe column data types\n",
      "Index(['review_id', 'title', 'year', 'user_review', 'user_suggestion'], dtype='object')\n",
      "Index(['review_id', 'title', 'year', 'user_review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Return column names as Index object.\n",
    "print(\"Dataframe column data types\")\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target variable\n",
      "1    9968\n",
      "0    7526\n",
      "Name: user_suggestion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution of target available.\n",
    "print(\"Distribution of target variable\")\n",
    "print(df_train.user_suggestion.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of title variable\n",
      "Robocraft                                             842\n",
      "Eternal Card Game                                     791\n",
      "Heroes & Generals                                     745\n",
      "War Thunder                                           720\n",
      "Fractured Space                                       718\n",
      "Bless Online                                          712\n",
      "The Elder Scrolls®: Legends™                          565\n",
      "Neverwinter                                           546\n",
      "AdventureQuest 3D                                     519\n",
      "theHunter Classic                                     518\n",
      "Creativerse                                           492\n",
      "DCS World Steam Edition                               488\n",
      "Infestation: The New Z                                479\n",
      "Team Fortress 2                                       479\n",
      "PlanetSide 2                                          472\n",
      "Path of Exile                                         458\n",
      "SMITE®                                                454\n",
      "Fallout Shelter                                       447\n",
      "Realm Royale                                          442\n",
      "Trove                                                 430\n",
      "Ring of Elysium                                       419\n",
      "RaceRoom Racing Experience                            416\n",
      "Brawlhalla                                            410\n",
      "Dota 2                                                405\n",
      "Yu-Gi-Oh! Duel Links                                  399\n",
      "Cuisine Royale                                        399\n",
      "Spooky's Jump Scare Mansion                           362\n",
      "Elsword                                               342\n",
      "Realm of the Mad God                                  340\n",
      "World of Tanks Blitz                                  327\n",
      "WARMODE                                               300\n",
      "World of Guns: Gun Disassembly                        293\n",
      "Black Squad                                           288\n",
      "School of Dragons                                     268\n",
      "Bloons TD Battles                                     233\n",
      "Sakura Clicker                                        222\n",
      "Business Tour - Board Game with Online Multiplayer    191\n",
      "Realm Grinder                                         155\n",
      "Crusaders of the Lost Idols                           132\n",
      "EverQuest II                                           69\n",
      "Dreadnought                                            60\n",
      "Freestyle 2: Street Basketball                         57\n",
      "Shop Heroes                                            52\n",
      "Tactical Monsters Rumble Arena                         38\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution of title variable.\n",
    "print(\"Distribution of title variable\")\n",
    "print(df_train.title.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting all letters to lowercase\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting all letters to lowercase\")\n",
    "# Convert text to lowercase.\n",
    "def tolowercase(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(tolowercase)\n",
    "df_test['user_review'] = df_test.user_review.apply(tolowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing punctuation\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing punctuation\")\n",
    "\n",
    "# Remove punctuation.\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(remove_punctuation)\n",
    "df_test['user_review'] = df_test.user_review.apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform lemmatization\n"
     ]
    }
   ],
   "source": [
    "print(\"Perform lemmatization\")\n",
    "\n",
    "# Lemmatization:\n",
    "def do_lemmatization(text):\n",
    "    lemma_words = set([])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = word_tokenize(text)\n",
    "    for word in text:\n",
    "        lemma_words.add(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "df_train['user_review'] = df_train.user_review.apply(do_lemmatization)\n",
    "df_test['user_review'] = df_test.user_review.apply(do_lemmatization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform named entity recognition\n",
      "(S\n",
      "  noob/RB\n",
      "  though/IN\n",
      "  wait/JJ\n",
      "  asoh/NN\n",
      "  i/NN\n",
      "  charactes/NNS\n",
      "  me/PRP\n",
      "  time/NN\n",
      "  room/NN\n",
      "  were/VBD\n",
      "  bubble/JJ\n",
      "  look/NN\n",
      "  trying/VBG\n",
      "  turn/VB\n",
      "  them/PRP\n",
      "  review/VB\n",
      "  kill/VB\n",
      "  im/NN\n",
      "  at/IN\n",
      "  hello/JJ\n",
      "  finding/VBG\n",
      "  tree/NN\n",
      "  with/IN\n",
      "  that/DT\n",
      "  themor/NN\n",
      "  moment/NN\n",
      "  staring/VBG\n",
      "  there/RB\n",
      "  can/MD\n",
      "  stand/VB\n",
      "  such/JJ\n",
      "  whats/NNS\n",
      "  and/CC\n",
      "  write/JJ\n",
      "  heart/NN\n",
      "  for/IN\n",
      "  my/PRP$\n",
      "  beat/NN\n",
      "  full/JJ\n",
      "  thing/NN\n",
      "  friend/NN\n",
      "  adorable/JJ\n",
      "  afraid/NN\n",
      "  from/IN\n",
      "  isnot/JJ\n",
      "  atleast/NN\n",
      "  on/IN\n",
      "  voice/NN\n",
      "  while/IN\n",
      "  clean/JJ\n",
      "  like/IN\n",
      "  see/VBP\n",
      "  happy/JJ\n",
      "  to/TO\n",
      "  ghost/VB\n",
      "  the/DT\n",
      "  do/NN\n",
      "  flashlight/VBD\n",
      "  likable/JJ\n",
      "  hmm/NN\n",
      "  ill/NN\n",
      "  is/VBZ\n",
      "  pause/IN\n",
      "  creepy/NN\n",
      "  hearing/VBG\n",
      "  few/JJ\n",
      "  before/IN\n",
      "  1990swhat/CD\n",
      "  did/VBD\n",
      "  locked/VBN\n",
      "  so/RB\n",
      "  class/NN\n",
      "  music/NN\n",
      "  scared/VBD\n",
      "  a/DT\n",
      "  if/IN\n",
      "  bit/NN\n",
      "  around/RB\n",
      "  in/IN\n",
      "  chasing/VBG\n",
      "  been/VBN\n",
      "  of/IN\n",
      "  somewhat/RB\n",
      "  more/RBR\n",
      "  this/DT\n",
      "  dead/JJ\n",
      "  but/CC\n",
      "  child/JJ\n",
      "  menever/NN\n",
      "  calmer/NN\n",
      "  odd/IN\n",
      "  childhood/NN\n",
      "  game/NN\n",
      "  door/NN\n",
      "  return/VBP\n",
      "  shine/NN\n",
      "  graphic/NNS\n",
      "  have/VBP\n",
      "  sceme/VBN\n",
      "  let/NN\n",
      "  are/VBP)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perform named entity recognition\")\n",
    "\n",
    "def named_entity_recognition(text):\n",
    "    result = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    return result\n",
    "\n",
    "text_1 = df_train.user_review[0]\n",
    "ner = named_entity_recognition(text_1)\n",
    "print(ner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of-speech tagging using NLTK\n",
      "0        [(noob, RB), (though, IN), (wait, JJ), (asoh, ...\n",
      "1        [(youtube, VB), (a, DT), (consuming, VBG), (it...\n",
      "2        [(on, IN), (a, DT), (it, PRP), (finish, JJ), (...\n",
      "3        [(cheer, NN), (shame, NN), (fullscreen, JJ), (...\n",
      "4        [(on, IN), (steami, NN), (first, RB), (close, ...\n",
      "                               ...                        \n",
      "17489    [(little, JJ), (free, JJ), (need, NN), (quest,...\n",
      "17490    [(ton, NN), (credit, NN), (free, JJ), (need, V...\n",
      "17491    [(day, NN), (reason, NN), (i, NN), (4000, CD),...\n",
      "17492    [(on, IN), (livid, NN), (it, PRP), (most, RBS)...\n",
      "17493    [(first, RB), (lmao, JJ), (remember, VB), (a, ...\n",
      "Name: pos_tagging, Length: 17494, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Part-of-speech tagging using NLTK\")\n",
    "\n",
    "def pos_tagging(text):\n",
    "    text = word_tokenize(text)\n",
    "    tokens_tag = pos_tag(text)\n",
    "    return tokens_tag\n",
    "\n",
    "df_train['pos_tagging'] = df_train.user_review.apply(pos_tagging)\n",
    "print(df_train['pos_tagging'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 15380), ('game', 15306), ('and', 14988), ('to', 14676), ('a', 13856), ('it', 13690), ('is', 12969), ('of', 12413), ('this', 12316), ('i', 11821), ('you', 11249), ('for', 10458), ('in', 10094), ('but', 9713), ('that', 9446)]\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF 15 MOST FREQUENT TERMS.\n",
    "token = nltk.word_tokenize(''.join(df_train.user_review))\n",
    "frequent = nltk.FreqDist(token)\n",
    "print(frequent.most_common(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of word 587\n",
      "\n",
      "Sentence:\n",
      " ['3rd foot abducted jesus word invite serve china milan 2nd you atlantis resurrected food also biogenetic vyacheslav crucified say bishop remain standing rico wanted medicine super kill church image old sergiy 7525 per same hurry mudra basically away vote now giant ocean administered hit can there youll hebrew chamber or baikal 2inside cross which airplane germany ufo hence long natural he about isi youre done ic blame when nika water satan swallow german sold ha go one cant clothfabrictextile correctly him greenland like zombie holy guardian see tell read to jew govt good five azazel supreme few patriarch into lower muslim switch behind chunk closet wa lake nine leader planetary body dinosaur stove blood lenin try through hide if believe inviting collapse flat in of document both plate short infirmitiesillnessessicknesses level wound proper prison run care but religion nanochips god 8 return weather eurasia taken dont pose angel let come are 1st sample ice slavonic hand not 7 rocket next clone conquers saint hexagram bigger than disease only kailash pray aborted nerve 12 woodburning crowbar allegiance dusha wolf first ruski those with crowned whole 666 radiation save grow skin sionists eye participate for what american bread twisted base prayer menachem up created surround wear heretic stranded these power poison except antarctica by from plague robe abduct meet abduction siberia russia possessed 4in pay planet enoch fully diamond ural your make volga high leg past panic tsar is stay very blow zodiac river back so catholic soldier worship earthquake 8th transfer ago fake person against orthodox a megatsunamis want longer roman depicted maya bunch country alaska inside superpower 200 nuke this 11th 2016 fast knife sarov live oh fall christian groin cover israeli other preach temple horoscope krasheninnikov america thru need killed pole intelligence drunk clothing filling october sometimes dy inspired fear time ryazan flag take scandinavia shroud cut thought here forward 2 were burned devil shake seraph radonezh costume allows eat all life them predicted bacteriologist medical last cortes discovered across prophet that pillar each left nato and clergy aggression 1km etc attack spirit lot inland orthodoxy mountain tectonic appear acknowledging turkey sign his clothes no light disagree weapon sinkhole higher 2006 on after 36 scientist meeting hole order healed shovel christ plus incorrectly false schneerson trench do rejecting where blasphemer commonly bomb who blasphemy yersin elijah himself our passion before main an saying happens world others stop metal unmeltable 1066 step craft together ad melt fight eldeity abyss pelageya coast three council doesnt finger trapped move euro stick they bug logic alien stadiumsize fetus turin down quiet underneath holiday bring use people reject dream sin italian instead june mercy repeatedly energy deceived month keep earth triple 4 nail clothed alexandre result always satanic iran belief vaccine destroy iv then look show trinity pale chinese be just 1moon at mariana satanist tube dna off put biggest upside antichrist implant it week 666ed being freeze trait stand betraying crossing curse showing yosef priest sleep my symbol side surrounded cell 3 mendel exhibit santa human during many bowing signed synthetic glove never fly slowly tibet service secret while over most kelvin elect massive anathema creation liberty ww3 bird used the their blue kneeling ukraine portuguese gaad war right creator zero statue learn way spanish xc chest language chanted communion under out demon fuel because designed 10001500 soul airspace big stripper head shoulder third crowning icon year u more between normal bubonic provides 3in pacific since without buddhist sky get tired new will either nobody have another celcius wont red']\n"
     ]
    }
   ],
   "source": [
    "# Text with highest number of words.\n",
    "df_train['number_of_words'] = df_train['user_review'].apply(lambda x: len(str(x).split()))\n",
    "print('Maximum number of word',df_train['number_of_words'].max())\n",
    "print('\\nSentence:\\n',df_train[df_train['number_of_words'] == 587]['user_review'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13995,)\n",
      "(3499,)\n",
      "(13995,)\n",
      "(3499,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train['user_review']\n",
    "y = df_train['user_suggestion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(13995, 5000)\n",
      "(3499, 5000)\n",
      "(8045, 5000)\n"
     ]
    }
   ],
   "source": [
    "# # Feature Extraction using TFIDF-Char Based.\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), stop_words='english', analyzer='char',max_features=5000)\n",
    "print(type(tfidf_vec))  # TfidfVectorizer class.\n",
    "train_tfidf_vec = tfidf_vec.fit_transform(X_train)\n",
    "print(type(train_tfidf_vec))  # Sparse CSR matrix.\n",
    "valid_tfidf_vec = tfidf_vec.transform(X_test)\n",
    "print(type(valid_tfidf_vec))  # Sparse CSR matrix.\n",
    "test_tfidf_vec = tfidf_vec.transform(df_test['user_review'])\n",
    "train_vector_array = train_tfidf_vec.toarray()\n",
    "valid_vector_array = valid_tfidf_vec.toarray()\n",
    "test_vector_array = test_tfidf_vec.toarray()\n",
    "\n",
    "print(train_vector_array.shape)\n",
    "print(valid_vector_array.shape)\n",
    "print(test_vector_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8250928836810517\n"
     ]
    }
   ],
   "source": [
    "# Linear support vector classifier.\n",
    "lsvc = LinearSVC(C=1,loss= 'hinge',random_state=999)\n",
    "lsvc.fit(train_vector_array, y_train)\n",
    "y_pred = lsvc.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))   # 0.8250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122320663046585\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression.\n",
    "lr = LogisticRegression(random_state=999)\n",
    "lr.fit(train_vector_array, y_train)\n",
    "y_pred = lr.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.8128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826882966396292\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier.\n",
    "rfc = RandomForestClassifier(n_estimators=300, random_state=999)\n",
    "rfc.fit(train_vector_array, y_train)\n",
    "pred = rfc.predict(valid_vector_array)\n",
    "print(f1_score(y_test, pred))  # 0.8270\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649042583595313\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes.\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(train_vector_array,y_train)\n",
    "y_pred = bnb.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.6547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8328093741068877\n"
     ]
    }
   ],
   "source": [
    "# Ridge Classifier.\n",
    "ridge = RidgeClassifier(random_state=999)\n",
    "ridge.fit(train_vector_array,y_train)\n",
    "y_pred = ridge.predict(valid_vector_array)\n",
    "print(f1_score(y_test,y_pred,average='micro'))  # 0.8348\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_final = ridge.predict((test_vector_array))\n",
    "df = pd.DataFrame({'review_id': df_test['review_id'], 'user_suggestion': pred_final})\n",
    "df.to_csv(\"submission_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19392)\t1\n",
      "  (0, 2953)\t1\n",
      "  (0, 5516)\t1\n",
      "  (0, 18572)\t1\n",
      "  (0, 18389)\t1\n",
      "  (0, 2816)\t1\n",
      "  (0, 15277)\t1\n",
      "  (0, 7996)\t1\n",
      "  (0, 8966)\t1\n",
      "  (0, 8320)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 18426)\t1\n",
      "  (0, 13755)\t1\n",
      "  (0, 18618)\t1\n",
      "  (0, 1325)\t1\n",
      "  (0, 9297)\t1\n",
      "  (0, 796)\t1\n",
      "  (0, 18661)\t1\n",
      "  (0, 2358)\t1\n",
      "  (1, 260)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 7306)\t1\n",
      "  (1, 6905)\t1\n",
      "  (1, 3265)\t1\n",
      "  (1, 8031)\t1\n",
      "  :\t:\n",
      "  (13994, 2848)\t1\n",
      "  (13994, 5619)\t1\n",
      "  (13994, 10803)\t1\n",
      "  (13994, 6974)\t1\n",
      "  (13994, 1532)\t1\n",
      "  (13994, 16951)\t1\n",
      "  (13994, 16978)\t1\n",
      "  (13994, 12286)\t1\n",
      "  (13994, 16455)\t1\n",
      "  (13994, 8247)\t1\n",
      "  (13994, 14371)\t1\n",
      "  (13994, 7565)\t1\n",
      "  (13994, 12703)\t1\n",
      "  (13994, 11531)\t1\n",
      "  (13994, 19458)\t1\n",
      "  (13994, 10333)\t1\n",
      "  (13994, 19408)\t1\n",
      "  (13994, 15822)\t1\n",
      "  (13994, 11806)\t1\n",
      "  (13994, 13418)\t1\n",
      "  (13994, 19409)\t1\n",
      "  (13994, 16924)\t1\n",
      "  (13994, 4395)\t1\n",
      "  (13994, 4024)\t1\n",
      "  (13994, 15697)\t1\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# LDA Topic Modelling:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(X_train)\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._lda.LatentDirichletAllocation'>\n",
      "[[1.50392197 0.20285865 0.20000048 ... 0.20001073 0.20001242 0.20000421]\n",
      " [2.22030621 9.26054728 0.20059775 ... 0.2019053  1.19880946 4.19996877]\n",
      " [0.2029754  0.20583334 0.20000148 ... 0.20003713 0.2000419  0.20001373]\n",
      " [1.87005562 0.21013206 0.20395717 ... 2.19803437 1.20111946 0.20000869]\n",
      " [0.2027408  2.12062867 2.19544313 ... 0.20001246 0.20001676 0.20000461]]\n"
     ]
    }
   ],
   "source": [
    "# Each of x documents is represented as y dimensional vector,which means that our vocabulary has y words.\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "LDA = LatentDirichletAllocation(n_components=5,\n",
    "                                random_state=0)\n",
    "print(type(LDA))  # LatentDirichletAllocation class.\n",
    "LDA.fit(doc_term_matrix)\n",
    "print(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "[1.50392197 0.20285865 0.20000048 ... 0.20001073 0.20001242 0.20000421]\n",
      "\n",
      "Topic #0:\n",
      "[('just', 1246.229357490189), ('play', 1238.2028233219066), ('like', 1233.0199735780132), ('money', 1164.4577990595271), ('time', 1160.5062199639926), ('dont', 1113.8961971124888), ('pay', 982.8027046425151), ('fun', 982.7455095978148), ('free', 955.670815045312), ('want', 938.6225372268915), ('buy', 835.6175458444825), ('really', 808.7895968052771), ('make', 800.7320921994693), ('good', 777.9739181608712), ('thing', 761.2893860360768), ('need', 755.7732242094703), ('playing', 714.0867502575874), ('real', 693.6838553295981), ('people', 682.5548089004309), ('hour', 677.0993088320374), ('spend', 635.7362837314637), ('way', 617.0253866954621), ('lot', 612.7801510685401), ('player', 607.7477914293896), ('ha', 606.5678635337416), ('level', 577.0491998010422), ('new', 560.4528272964618), ('item', 543.9535131112646), ('win', 540.9006571508493), ('youre', 499.736157309247), ('great', 474.1922716557881), ('character', 473.72227898803123), ('pretty', 459.56474302760637), ('wa', 453.3193962385939), ('use', 438.08514163653234), ('better', 437.6988464294011), ('think', 437.2891172050668), ('feel', 428.2461333507135), ('try', 421.8940934698779), ('best', 414.2831276975346), ('know', 409.6487143309195), ('worth', 407.1492414865639), ('stuff', 405.7766569234922), ('recommend', 397.13591329667366), ('thats', 394.5172936902746), ('say', 372.973023789911), ('start', 368.3928749782211), ('played', 365.4226643305543), ('quest', 363.47243198138926), ('im', 362.40895162167163)]\n",
      "======================================================================\n",
      "[2.22030621 9.26054728 0.20059775 ... 0.2019053  1.19880946 4.19996877]\n",
      "\n",
      "Topic #1:\n",
      "[('access', 4028.9154990440275), ('early', 3885.650418285507), ('just', 2262.0405358039043), ('like', 2257.823476026572), ('wa', 2220.6520161682006), ('play', 2213.634899264168), ('dont', 1736.5758658484285), ('time', 1733.271031710507), ('good', 1701.9487336956208), ('fun', 1467.9829184200034), ('ha', 1391.5139394044386), ('really', 1282.5314858133854), ('make', 1203.4945738526858), ('playing', 1175.5708096638173), ('played', 1093.0370175160756), ('people', 1040.1329804895197), ('thing', 1021.1396518470351), ('im', 949.8531701333226), ('new', 934.531810633271), ('got', 918.3328700510973), ('bad', 892.6942668731193), ('hour', 864.1279998059949), ('better', 853.1558985322989), ('say', 848.4885699047053), ('great', 842.3239649054578), ('player', 838.3155338177467), ('update', 825.0504474613456), ('know', 779.6256250137143), ('want', 747.4782999144044), ('free', 714.9271609804115), ('need', 713.7354363545797), ('review', 712.6141119798635), ('server', 704.209585165509), ('way', 643.3092368932037), ('think', 628.5809420602613), ('lot', 622.3466372476926), ('year', 616.13845146921), ('recommend', 606.738897928544), ('love', 585.2199813282755), ('reviewi', 584.7351287674354), ('reviewthis', 584.6905452043426), ('day', 584.0970244048536), ('try', 574.1739701473853), ('look', 566.7903653363641), ('feel', 564.9310238505343), ('friend', 562.5630320554412), ('ive', 558.6745743429332), ('steam', 554.0127432893528), ('money', 552.9055513706447), ('going', 537.4627864944131)]\n",
      "======================================================================\n",
      "[0.2029754  0.20583334 0.20000148 ... 0.20003713 0.2000419  0.20001373]\n",
      "\n",
      "Topic #2:\n",
      "[('card', 911.4493892719819), ('early', 551.0706265470061), ('deck', 542.5088641084391), ('access', 536.2744423334304), ('hearthstone', 426.6816081308939), ('play', 398.7011931922845), ('time', 330.5566764592931), ('magic', 305.1834007422248), ('like', 278.75919105360316), ('ha', 254.89261421817346), ('player', 224.65887587240294), ('just', 215.56637109158547), ('played', 211.54987728886513), ('mtg', 210.09220296494496), ('mechanic', 208.12705003434516), ('make', 198.69094635227592), ('turn', 196.0101245808273), ('way', 185.60363114280347), ('opponent', 180.7949150354875), ('wa', 174.96382312700152), ('playing', 172.749238742558), ('mobile', 165.72483635717327), ('draw', 158.1541389046522), ('mana', 155.1286851460892), ('mode', 154.35155143545276), ('fun', 148.9214206984164), ('good', 148.82130060188138), ('eternal', 147.08843788177967), ('dont', 146.57397997751173), ('gathering', 142.786583416702), ('win', 141.41308671298654), ('generous', 141.29223038256387), ('scroll', 139.72429684361242), ('doesnt', 137.71134980790788), ('free', 133.42981607178714), ('ive', 133.40059785402684), ('pack', 132.24248673320213), ('elder', 131.03830066756817), ('really', 129.1820169267563), ('reward', 127.56456880979742), ('rng', 123.5190162846796), ('digital', 120.49941595460069), ('ccg', 120.34548805968198), ('great', 118.76805499037587), ('yugioh', 118.76552133500111), ('ai', 118.24795348507206), ('lot', 117.55573416066554), ('start', 115.15243835019022), ('set', 113.62474721308007), ('im', 112.50867234039946)]\n",
      "======================================================================\n",
      "[1.87005562 0.21013206 0.20395717 ... 2.19803437 1.20111946 0.20000869]\n",
      "\n",
      "Topic #3:\n",
      "[('play', 1125.0055779957686), ('like', 1019.4936708874733), ('fun', 838.4248903403146), ('free', 835.4917733431356), ('great', 786.3266395204225), ('good', 745.4697690886169), ('ha', 716.474724975291), ('best', 628.2221700648299), ('lot', 586.6488806243897), ('played', 585.5360041471281), ('really', 578.4331036362986), ('time', 550.9211388243637), ('recommend', 539.1841632546442), ('graphic', 480.1785719489131), ('gameplay', 450.2372802849592), ('ive', 438.4166952739557), ('playing', 435.6051594928863), ('just', 435.1319156535679), ('feel', 408.79702874117135), ('friend', 404.3512813394568), ('love', 391.6490860569363), ('new', 384.13387255863427), ('try', 380.889823946425), ('player', 366.53823598905103), ('pretty', 340.4814939389731), ('different', 339.7610513990079), ('better', 336.81407666591866), ('character', 335.47461877290306), ('thing', 328.1704486807722), ('make', 324.01247718671306), ('amazing', 319.1091377076652), ('community', 318.75484187576876), ('style', 299.92609003209077), ('say', 291.46159959555905), ('bit', 285.04634007470634), ('early', 284.4515267543685), ('access', 277.9043960470074), ('look', 277.0835570457857), ('highly', 273.79080823586486), ('nice', 272.11979913351865), ('hour', 269.2470742467885), ('experience', 263.4164986944384), ('moba', 263.059089781165), ('unique', 259.33915076079364), ('ship', 251.05005874045102), ('want', 240.66009110200895), ('enjoy', 239.4730621514458), ('need', 238.42657314863624), ('skill', 234.51567844185428), ('dont', 234.11114090379596)]\n",
      "======================================================================\n",
      "[0.2027408  2.12062867 2.19544313 ... 0.20001246 0.20001676 0.20000461]\n",
      "\n",
      "Topic #4:\n",
      "[('tank', 832.0682152479366), ('player', 820.7395628912589), ('just', 777.0318199606052), ('play', 746.4555062257177), ('like', 714.9036884541769), ('time', 706.7449330416912), ('ha', 668.5508578682034), ('weapon', 622.6365313957414), ('good', 605.7862784528627), ('dont', 594.8428161576206), ('team', 592.9180686535458), ('make', 572.0699104087012), ('want', 522.4702418189446), ('thing', 516.0766741795728), ('money', 507.7845893174024), ('wa', 499.628228922359), ('people', 493.2482989311707), ('new', 488.24814239057827), ('way', 484.2769164893685), ('kill', 478.8190997118627), ('vehicle', 475.88418352942944), ('battle', 468.9257841323637), ('gun', 468.76608193811455), ('point', 457.5102949750865), ('enemy', 450.2307291623946), ('match', 450.19444551050293), ('fun', 428.9252609432939), ('map', 427.6913852571503), ('win', 410.8697409005656), ('pay', 400.5025720946506), ('better', 386.14494807296614), ('plane', 385.4831089892794), ('war', 383.3388434347627), ('really', 381.0637968181333), ('hour', 375.23708248024053), ('playing', 369.9880418429977), ('tier', 362.49689742707966), ('use', 355.9391843025519), ('buy', 344.39652047374057), ('grind', 344.2259717106846), ('need', 323.47184596217727), ('shot', 317.97531996849773), ('lot', 315.66859689856267), ('damage', 310.84314121895625), ('start', 294.0560575456319), ('real', 290.7646430073934), ('year', 289.88114635315407), ('bad', 287.6450081207636), ('long', 283.1755460897508), ('premium', 281.70339315671197)]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# For each topic,each word of the document is assigned a weight.\n",
    "# Higher weight means it is the top word of the topic.\n",
    "# It is a multidimensional array.Each row represent the topic,each column represents the word in a document.\n",
    "# Shape = [n_topics,n_words] or [n_components, n_features]\n",
    "\n",
    "# Define helper function to print top words for each topic.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        print(topic)\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        print(message)\n",
    "        print([(feature_names[i], topic[i]) for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        # feature_names[i] is a word,topic[i] is the weight of the word for that topic.\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "number_of_words = 50\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = count_vect.get_feature_names()\n",
    "print_top_words(LDA, tf_feature_names, number_of_words)\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2358)\t0.10471240034982547\n",
      "  (0, 18661)\t0.08573368833073064\n",
      "  (0, 796)\t0.1606282261167631\n",
      "  (0, 9297)\t0.3425246833049525\n",
      "  (0, 1325)\t0.3425246833049525\n",
      "  (0, 18618)\t0.2841761231572764\n",
      "  (0, 13755)\t0.09000125920816517\n",
      "  (0, 18426)\t0.33209505779521536\n",
      "  (0, 45)\t0.17755586664389592\n",
      "  (0, 8320)\t0.2351464758651997\n",
      "  (0, 8966)\t0.27963845872269194\n",
      "  (0, 7996)\t0.33209505779521536\n",
      "  (0, 15277)\t0.29542047955612927\n",
      "  (0, 2816)\t0.14753762362275624\n",
      "  (0, 18389)\t0.1335134519770323\n",
      "  (0, 18572)\t0.17755586664389592\n",
      "  (0, 5516)\t0.13709405694814777\n",
      "  (0, 2953)\t0.16127419418700661\n",
      "  (0, 19392)\t0.20878805199845787\n",
      "  (1, 7055)\t0.0833092203282156\n",
      "  (1, 13816)\t0.1761806733927889\n",
      "  (1, 11877)\t0.1448339864040923\n",
      "  (1, 12308)\t0.24169711031393992\n",
      "  (1, 1430)\t0.17229413574499436\n",
      "  (1, 13256)\t0.17080697734720654\n",
      "  :\t:\n",
      "  (13994, 1532)\t0.14086247789798925\n",
      "  (13994, 6974)\t0.1366547211499745\n",
      "  (13994, 10803)\t0.12911524767253468\n",
      "  (13994, 5619)\t0.18799404319370158\n",
      "  (13994, 2848)\t0.17367403228416955\n",
      "  (13994, 1949)\t0.08855918278866276\n",
      "  (13994, 5701)\t0.1361487192238249\n",
      "  (13994, 13542)\t0.1080129287070655\n",
      "  (13994, 13721)\t0.10635454962268495\n",
      "  (13994, 9627)\t0.08285023699843147\n",
      "  (13994, 18684)\t0.12541023094741408\n",
      "  (13994, 11342)\t0.09771893446891086\n",
      "  (13994, 9922)\t0.0774906719228895\n",
      "  (13994, 588)\t0.1162290207410189\n",
      "  (13994, 525)\t0.10635454962268495\n",
      "  (13994, 9959)\t0.08907892663657707\n",
      "  (13994, 14939)\t0.08104798433754734\n",
      "  (13994, 9788)\t0.101951579180234\n",
      "  (13994, 19357)\t0.09044975888406194\n",
      "  (13994, 1804)\t0.10348156566860879\n",
      "  (13994, 14859)\t0.10602391022887064\n",
      "  (13994, 10152)\t0.07467900678069897\n",
      "  (13994, 837)\t0.0459418068301555\n",
      "  (13994, 5489)\t0.04650894748952957\n",
      "  (13994, 17490)\t0.048190507353686296\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Topic Modelling : NMF: Non-Matrix factorization.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = tfidf_vect.fit_transform(X_train)\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._nmf.NMF'>\n",
      "[[0.00171902 0.0027099  0.00031854 ... 0.         0.         0.00199683]\n",
      " [0.         0.         0.00044252 ... 0.00990441 0.00315435 0.        ]\n",
      " [0.         0.00081488 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00186065 0.         ... 0.         0.         0.        ]\n",
      " [0.00225753 0.00293271 0.0002522  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "print(type(nmf))\n",
    "nmf.fit(doc_term_matrix)\n",
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model: \n",
      "\n",
      "Topic #0:\n",
      "[('fun', 0.9281842024008652), ('play', 0.8083239228961133), ('great', 0.7745282107161601), ('really', 0.7469751606270667), ('good', 0.7215021616895365), ('like', 0.7168866091663078), ('free', 0.6476114353880457), ('recommend', 0.6410729028072912), ('friend', 0.608829635068762), ('lot', 0.576119788054637), ('best', 0.5495056632441325), ('graphic', 0.5459725969982037), ('love', 0.5323032329703352), ('played', 0.5319209500998807), ('playing', 0.4186492408420217), ('pretty', 0.41519243811565365), ('try', 0.3926006297527687), ('amazing', 0.38705525534223373), ('nice', 0.3720721247253306), ('feel', 0.36401550345093103), ('ha', 0.36314398467153675), ('gameplay', 0.33267289622080454), ('ive', 0.3318293033970283), ('character', 0.3283686219637906), ('time', 0.3261920193971395), ('thing', 0.3157451453845419), ('bit', 0.3041530169123949), ('better', 0.2986542020509058), ('overall', 0.28044617065728195), ('look', 0.27992350785384595), ('just', 0.2769460668447932), ('world', 0.2762135048547485), ('enjoy', 0.2614685983855143), ('think', 0.2591165879647218), ('easy', 0.2569107673522746), ('little', 0.25312549534717704), ('different', 0.24722771077660302), ('highly', 0.24574074771074753), ('awesome', 0.2368588426452471), ('looking', 0.23132401836933908), ('style', 0.22127438462646867), ('quite', 0.21998706536108453), ('people', 0.21465118818193626), ('say', 0.2138092081333911), ('fan', 0.21066949199813556), ('worth', 0.20972745737103027), ('far', 0.20922132661492732), ('class', 0.20495534821295325), ('definitely', 0.2041665538469902), ('cool', 0.20369176864527733)]\n",
      "======================================================================\n",
      "\n",
      "Topic #1:\n",
      "[('access', 1.8658147622280838), ('early', 1.8429094819232676), ('reviewthis', 0.652452775051178), ('reviewi', 0.5196742917337082), ('pubg', 0.26054700136827535), ('reviewthe', 0.25503944234401077), ('royale', 0.24776977500784922), ('good', 0.240925071261486), ('wa', 0.20333967944580858), ('like', 0.1992336095998406), ('battle', 0.19320702107762802), ('update', 0.1822089722243003), ('fortnite', 0.17710684857486203), ('fun', 0.17453480719534278), ('reviewits', 0.17010759206499937), ('weapon', 0.1645142611761953), ('alpha', 0.15959225229951038), ('ha', 0.13935909510373073), ('better', 0.1307933016091974), ('ship', 0.1294018861580193), ('play', 0.12613267186452348), ('just', 0.12541305227306085), ('potential', 0.12241540642928901), ('devs', 0.12226821561427398), ('hope', 0.11763238905432892), ('fps', 0.1138486850519626), ('dont', 0.1078130531492003), ('server', 0.10564850290257809), ('smash', 0.10169816701863252), ('gun', 0.1006544813107958), ('csgo', 0.1000966167298457), ('reviewgreat', 0.09922123527652117), ('review', 0.09782537740796189), ('bug', 0.09751638313188427), ('space', 0.0973561446234648), ('great', 0.09687080616546825), ('reviewit', 0.0943460332383401), ('freeearly', 0.09409162515839785), ('br', 0.09216780893775486), ('fix', 0.09205887366124108), ('bros', 0.08657587037385586), ('bad', 0.08625923120751247), ('issue', 0.08623078790584635), ('wait', 0.08604193939558179), ('awesome', 0.0840430038834088), ('really', 0.08386918452505432), ('need', 0.08375297592408236), ('robocraft', 0.07978744136237335), ('reviewvery', 0.07977968861383279), ('movement', 0.07972461164935106)]\n",
      "======================================================================\n",
      "\n",
      "Topic #2:\n",
      "[('card', 1.1431861042491365), ('hearthstone', 0.7373095379719958), ('deck', 0.72875486964109), ('magic', 0.5135011227522949), ('mtg', 0.40820998680499715), ('gathering', 0.30624644405629475), ('generous', 0.30474880946357763), ('mechanic', 0.30306914465721496), ('pack', 0.2670015772041726), ('elder', 0.26349868344823096), ('eternal', 0.25622475082383056), ('scroll', 0.2546590433556046), ('mana', 0.25027089123622026), ('ccg', 0.23293859746126483), ('player', 0.227171201871042), ('mode', 0.22601149730153375), ('digital', 0.2256906201393642), ('reward', 0.2247100738522471), ('f2p', 0.20034740793049094), ('draft', 0.20008660887630642), ('rng', 0.19747388990025302), ('opponent', 0.19593668115570387), ('draw', 0.1917896934268028), ('strategy', 0.18202399718134935), ('ai', 0.18166833265851773), ('arena', 0.17853767059376005), ('easy', 0.16564890818184957), ('story', 0.16411987671284697), ('ranked', 0.16314208950536885), ('build', 0.1552706511907539), ('interesting', 0.1546512742473063), ('turn', 0.15399435311730394), ('best', 0.15323054027819594), ('legend', 0.15315352721685377), ('collection', 0.1520205374772202), ('playing', 0.15157840271990422), ('win', 0.1502225941902788), ('gold', 0.145279063173385), ('play', 0.14463952635617355), ('ha', 0.14439125658993368), ('meta', 0.142702929419313), ('played', 0.14031561128134953), ('campaign', 0.1390856985325034), ('like', 0.13297019808960364), ('depth', 0.13219051394822945), ('lot', 0.13140120816988515), ('way', 0.12719680815274118), ('power', 0.12601857441036385), ('new', 0.1254224920676787), ('online', 0.11986822940598557)]\n",
      "======================================================================\n",
      "\n",
      "Topic #3:\n",
      "[('pay', 1.1179665015653426), ('money', 1.0208503424436468), ('win', 0.7045216007731444), ('buy', 0.6727339807802303), ('real', 0.5181114976820801), ('dont', 0.48932161903463567), ('want', 0.4715773197702481), ('spend', 0.4419444627286145), ('free', 0.422514221832026), ('play', 0.3469900351774339), ('need', 0.3099282250524593), ('just', 0.2780074571138731), ('gun', 0.27728679870346173), ('unless', 0.276383481147463), ('animal', 0.2750098379817134), ('hunt', 0.2421614217788899), ('hunting', 0.2190408440873512), ('time', 0.21789322352360932), ('paying', 0.20710058664270795), ('fun', 0.20571487653641657), ('unlock', 0.2047353579494728), ('stuff', 0.20409362573535858), ('cost', 0.20167737228199292), ('waste', 0.1947239419418832), ('worth', 0.19318600165934802), ('grind', 0.1911260004012375), ('currency', 0.18859382757558246), ('people', 0.1760594148870258), ('hour', 0.17536629094031314), ('membership', 0.17212094945244724), ('premium', 0.1662975255764296), ('thing', 0.16435380522336196), ('weapon', 0.16116359385504908), ('item', 0.15807813926133865), ('spending', 0.15573857711948882), ('deer', 0.15524240511535745), ('ingame', 0.1539840822586251), ('good', 0.15116229590853958), ('better', 0.14969282332229195), ('like', 0.14824571978554155), ('cash', 0.14486925296314135), ('really', 0.14480362402603159), ('buying', 0.1354483880901189), ('make', 0.13412427944272315), ('expensive', 0.1338451632877697), ('price', 0.13250190275098667), ('f2p', 0.131568039746143), ('license', 0.13082797562990606), ('tank', 0.1283331803477874), ('earn', 0.12801926605580477)]\n",
      "======================================================================\n",
      "\n",
      "Topic #4:\n",
      "[('wa', 0.716123031686248), ('time', 0.5250129549341713), ('just', 0.5181473098674381), ('new', 0.47095067709521554), ('player', 0.45702628305604237), ('make', 0.41003590317146144), ('ha', 0.395113958363593), ('got', 0.39331933228090155), ('im', 0.3887458527076529), ('year', 0.38632875536723604), ('know', 0.3779422910162119), ('hour', 0.3757136316247005), ('people', 0.36769128889888714), ('dont', 0.35181932758231726), ('playing', 0.35087746362723526), ('update', 0.3505101859603637), ('way', 0.33674404624543414), ('review', 0.3343746166980428), ('thing', 0.32533638825722067), ('point', 0.31141807624044154), ('bad', 0.31084491975467105), ('long', 0.3069662331107847), ('say', 0.2997963212120119), ('change', 0.2965659339857029), ('server', 0.2936606899520068), ('going', 0.292604179142894), ('start', 0.2921277776040113), ('did', 0.2898818866541651), ('getting', 0.2858371612261146), ('problem', 0.28556427248421434), ('day', 0.2850312237744208), ('team', 0.2847783468383839), ('used', 0.2743654378188397), ('issue', 0.27253253384101056), ('doesnt', 0.2712325170616215), ('match', 0.26974141303182525), ('minute', 0.2691406122685691), ('come', 0.2533286505811124), ('right', 0.2523374602210238), ('trying', 0.2514557705199717), ('fix', 0.2507270647914652), ('let', 0.2500586242119238), ('didnt', 0.24926974697262735), ('started', 0.24864559640943928), ('making', 0.24704422821333288), ('work', 0.2463771574364107), ('level', 0.24222419314135032), ('reason', 0.24166244072420273), ('devs', 0.24094212659503256), ('actually', 0.23827279295715262)]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# # For each topic,each word of the document is assigned a weight.\n",
    "# # Higher weight means it is the top word of the topic.\n",
    "# # It is a multidimensional array.Each row represent the topic,each column represents the word in a document.\n",
    "# Shape - [n_topics,n_words] or [n_components, n_features].\n",
    "# Factorization matrix.\n",
    "\n",
    "# Define helper function to print top words.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        print(message)\n",
    "        print([(feature_names[i], topic[i]) for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "number_of_words = 50\n",
    "print(\"\\nTopics in NMF model: \")\n",
    "tf_feature_names = tfidf_vect.get_feature_names()  # note that tf_vectorizer is an LemmaCountVectorizer object and with this command we get the whole dictionary of words\n",
    "print_top_words(nmf, tf_feature_names, number_of_words)\n",
    "\n",
    "######################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
